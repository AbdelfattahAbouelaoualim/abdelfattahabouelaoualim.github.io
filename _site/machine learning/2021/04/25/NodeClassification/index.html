<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="">
  <meta name="author" content="">
  <title>How to do node classification and choose important features</title>

  <link href="/css/milo.css" rel="stylesheet">
  <link href="/fontawesome-free-5.12.1-web/css/all.css" rel="stylesheet"> <!--load all styles -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css"
    integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous">
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js"
    integrity="sha384-9Nhn55MVVN0/4OFx7EE5kpFBPsEMZxKTCnA+4fqDmg12eCTqGi6+BB2LjY8brQxJ"
    crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js"
    integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>
</head>
<body>
<!-- Navigation -->

<nav class="navbar navbar-expand-lg navbar-light fixed-top" id="mainNav">
  <div class="container-fluid">
    <a class="navbar-brand" href="/">
      <img class="logo" src="/img/logo.png" alt="" />
    </a>
    <button class="navbar-toggler navbar-dark" type="button" data-toggle="collapse" data-target="#navbarResponsive">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbarResponsive">
      <ul class="navbar-nav ml-auto">
        <li class="nav-item">
          <a class="nav-link" href="/">Home</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="/about">About</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="/author">Author</a>
        </li>
      </ul>
    </div>
  </div>
</nav>

<style>
.navbar {
  background: rgba(0,0,0,0.8);
  backdrop-filter: blur(10px);
  transition: all 0.3s ease;
}

.navbar-brand img.logo {
  width: 150px;
  height: auto;
  transition: all 0.3s ease;
}

.nav-link {
  color: #fff !important;
  font-weight: 500;
  padding: 0.5rem 1rem;
  position: relative;
}

.nav-link::after {
  content: '';
  position: absolute;
  width: 0;
  height: 2px;
  bottom: 0;
  left: 50%;
  background: #EA950B;
  transition: all 0.3s ease;
}

.nav-link:hover::after {
  width: 100%;
  left: 0;
}

@media (max-width: 991px) {
  .navbar-collapse {
    background: rgba(0,0,0,0.9);
    padding: 1rem;
    border-radius: 0.5rem;
  }
}
</style>


  <main class="main pt-4" role="main">

    <div class="container">

      <div class="row">
        <div class="col-md-9">

          <article class="card mb-4">
            <header class="card-header text-center">
              <div class="card-meta">
                <span class="date">25 April 2021</span>
                <span class="categories">
                  
                    <a href="/categories/#Machine Learning">#Machine Learning</a>
                  
                </span>
              </div>
              <h1 class="card-title">How to do node classification and choose important features</h1>
            </header>

            
            <div class="card-img-wrapper">
              <img class="card-img" src="/img/NodeClassification.jpg" alt="How to do node classification and choose important features" />
            </div>
            

            <div class="card-body">
              <style>
  @import url('https://fonts.googleapis.com/css2?family=Roboto:wght@300&display=swap');
  
  body {
      font-family: 'Open Sans', sans-serif;
  }

  h1 {
    font-family: 'Roboto', sans-serif;
    color: #007bff;
    margin-top: 30px;
  }

  h3 {
    font-family: 'Roboto', sans-serif;
    color: #007bff;
    margin-top: 30px;
  }

  h4 {
    font-family: 'Roboto', sans-serif;
    color: #EA950B;
    margin-top: 30px;
  }

  pre {
    background-color: #f9f9f9;
    padding: 15px;
    border-radius: 5px;
  }
</style>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">networkx</span> <span class="k">as</span> <span class="n">nx</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">os</span>

<span class="kn">import</span> <span class="n">stellargraph</span> <span class="k">as</span> <span class="n">sg</span>
<span class="kn">from</span> <span class="n">stellargraph.mapper</span> <span class="kn">import</span> <span class="n">GraphSAGENodeGenerator</span>
<span class="kn">from</span> <span class="n">stellargraph.layer</span> <span class="kn">import</span> <span class="n">GraphSAGE</span>

<span class="kn">from</span> <span class="n">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span><span class="p">,</span> <span class="n">optimizers</span><span class="p">,</span> <span class="n">losses</span><span class="p">,</span> <span class="n">metrics</span><span class="p">,</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="n">sklearn</span> <span class="kn">import</span> <span class="n">model_selection</span>
<span class="kn">from</span> <span class="n">sklearn.utils</span> <span class="kn">import</span> <span class="n">class_weight</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">big_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">"</span><span class="s">/data/big_df_2.csv</span><span class="sh">"</span><span class="p">)</span>
<span class="n">big_df</span><span class="p">.</span><span class="nf">drop</span><span class="p">([</span><span class="sh">'</span><span class="s">Unnamed: 0</span><span class="sh">'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">big_df</span><span class="p">[</span><span class="sh">'</span><span class="s">Count</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">abs</span><span class="p">(</span><span class="n">big_df</span><span class="p">[</span><span class="sh">'</span><span class="s">count</span><span class="sh">'</span><span class="p">]</span><span class="o">-</span><span class="n">big_df</span><span class="p">[</span><span class="sh">'</span><span class="s">count</span><span class="sh">'</span><span class="p">].</span><span class="nf">mean</span><span class="p">())</span><span class="o">/</span><span class="n">big_df</span><span class="p">[</span><span class="sh">'</span><span class="s">count</span><span class="sh">'</span><span class="p">].</span><span class="nf">std</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">big_df</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">big_df_</span> <span class="o">=</span> <span class="n">big_df</span><span class="p">[</span><span class="n">big_df</span><span class="p">[</span><span class="sh">'</span><span class="s">depart</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ddf</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">"</span><span class="s">data/ddf_2.csv</span><span class="sh">"</span><span class="p">)</span>
<span class="n">ddf</span><span class="p">.</span><span class="nf">drop</span><span class="p">([</span><span class="sh">'</span><span class="s">Unnamed: 0</span><span class="sh">'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">ddf</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">big_G</span> <span class="o">=</span> <span class="n">nx</span><span class="p">.</span><span class="nc">Graph</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ddf</span><span class="p">.</span><span class="n">index</span><span class="p">:</span>
    <span class="n">big_G</span><span class="p">.</span><span class="nf">add_edge</span><span class="p">(</span><span class="n">ddf</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="sh">'</span><span class="s">IndividualId</span><span class="sh">'</span><span class="p">],</span> <span class="n">ddf</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="sh">'</span><span class="s">FatherIndividualId</span><span class="sh">'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">list_nodes</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">big_df</span><span class="p">[</span><span class="sh">'</span><span class="s">node</span><span class="sh">'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">big_G</span> <span class="o">=</span> <span class="n">big_G</span><span class="p">.</span><span class="nf">subgraph</span><span class="p">(</span><span class="n">list_nodes</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">list_nodes</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">big_G</span><span class="p">.</span><span class="nf">nodes</span><span class="p">())</span>
<span class="n">big_df</span> <span class="o">=</span> <span class="n">big_df</span><span class="p">[</span><span class="n">big_df</span><span class="p">[</span><span class="sh">'</span><span class="s">node</span><span class="sh">'</span><span class="p">].</span><span class="nf">isin</span><span class="p">(</span><span class="n">list_nodes</span><span class="p">)]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">big_df</span> <span class="o">=</span> <span class="n">big_df</span><span class="p">.</span><span class="nf">set_index</span><span class="p">(</span><span class="sh">'</span><span class="s">node</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_data</span><span class="p">,</span> <span class="n">test_data</span> <span class="o">=</span> <span class="n">model_selection</span><span class="p">.</span><span class="nf">train_test_split</span><span class="p">(</span><span class="n">big_df</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">big_df</span><span class="p">[</span><span class="sh">'</span><span class="s">conflict</span><span class="sh">'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_data</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">feature_names</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">eigen</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Count</span><span class="sh">'</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">node_features</span> <span class="o">=</span> <span class="n">big_df</span><span class="p">[</span><span class="n">feature_names</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">node_features</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">node_features</span><span class="p">.</span><span class="nf">describe</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">node_features</span><span class="p">.</span><span class="nf">info</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
Int64Index: 6780 entries, 10004 to 9972
Data columns (total 2 columns):
eigen    6780 non-null float64
Count    6780 non-null float64
dtypes: float64(2)
memory usage: 158.9 KB
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">G</span> <span class="o">=</span> <span class="n">sg</span><span class="p">.</span><span class="nc">StellarGraph</span><span class="p">(</span><span class="n">big_G</span><span class="p">,</span> <span class="n">node_features</span><span class="o">=</span><span class="n">node_features</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="n">G</span><span class="p">.</span><span class="nf">info</span><span class="p">())</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>StellarGraph: Undirected multigraph
 Nodes: 6780, Edges: 7623

 Node types:
  default: [6780]
    Edge types: default-default-&gt;default

 Edge types:
    default-default-&gt;default: [7623]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">options</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">'</span><span class="s">node_color</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">blue</span><span class="sh">'</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">node_size</span><span class="sh">'</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">width</span><span class="sh">'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    
<span class="p">}</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">18</span><span class="p">,</span><span class="mi">18</span><span class="p">))</span>
<span class="n">nx</span><span class="p">.</span><span class="nf">draw</span><span class="p">(</span><span class="n">big_G</span><span class="p">,</span> <span class="n">with_labels</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span> <span class="o">**</span><span class="n">options</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/img/Node_Prediction/output_28_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="nc">Counter</span><span class="p">(</span><span class="n">train_data</span><span class="p">[</span><span class="sh">'</span><span class="s">conflict</span><span class="sh">'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Counter({0.0: 3250, 1.0: 2174})
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">missingno</span> <span class="k">as</span> <span class="n">msno</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">msno</span><span class="p">.</span><span class="nf">bar</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/img/Node_Prediction/output_31_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="n">nx</span><span class="p">.</span><span class="nf">info</span><span class="p">(</span><span class="n">big_G</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Name: 
Type: Graph
Number of nodes: 741
Number of edges: 164
Average degree:   0.4426
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">80</span><span class="p">;</span> <span class="n">num_samples</span> <span class="o">=</span> <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">15</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">generator</span> <span class="o">=</span> <span class="nc">GraphSAGENodeGenerator</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_gen</span> <span class="o">=</span> <span class="n">generator</span><span class="p">.</span><span class="nf">flow</span><span class="p">(</span><span class="n">train_data</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">train_data</span><span class="p">[[</span><span class="sh">"</span><span class="s">conflict</span><span class="sh">"</span><span class="p">]]))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">graphsage_model</span> <span class="o">=</span> <span class="nc">GraphSAGE</span><span class="p">(</span>
    <span class="n">layer_sizes</span><span class="o">=</span><span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">],</span>
    <span class="n">generator</span><span class="o">=</span><span class="n">train_gen</span><span class="p">,</span>
    <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="c1">#aggregator=sg.layer.graphsage.MeanAggregator
</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#from keras import layers, optimizers, losses, metrics, Model
</span></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x_inp</span><span class="p">,</span> <span class="n">x_out</span> <span class="o">=</span> <span class="n">graphsage_model</span><span class="p">.</span><span class="nf">build</span><span class="p">()</span>

<span class="n">prediction</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="nc">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">train_data</span><span class="p">[[</span><span class="sh">"</span><span class="s">conflict</span><span class="sh">"</span><span class="p">]]).</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">activation</span><span class="o">=</span><span class="sh">"</span><span class="s">sigmoid</span><span class="sh">"</span><span class="p">)(</span><span class="n">x_out</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="nc">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">x_inp</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">prediction</span><span class="p">)</span>

<span class="n">model</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="nc">Adam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">),</span>
    <span class="n">loss</span><span class="o">=</span><span class="n">keras</span><span class="p">.</span><span class="n">losses</span><span class="p">.</span><span class="n">binary_crossentropy</span><span class="p">,</span>
    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">acc</span><span class="sh">"</span><span class="p">]</span>
<span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test_gen</span> <span class="o">=</span> <span class="n">generator</span><span class="p">.</span><span class="nf">flow</span><span class="p">(</span><span class="n">test_data</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">test_data</span><span class="p">[[</span><span class="sh">"</span><span class="s">conflict</span><span class="sh">"</span><span class="p">]]))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">fit_generator</span><span class="p">(</span>
    <span class="n">train_gen</span><span class="p">,</span>
    <span class="n">steps_per_epoch</span><span class="o">=</span><span class="nf">len</span><span class="p">(</span><span class="n">big_df</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="n">test_gen</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span>
<span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 1/25
84/84 - 5s - loss: 0.6341 - acc: 0.6411 - val_loss: 0.5891 - val_acc: 0.7139
Epoch 2/25
84/84 - 4s - loss: 0.5809 - acc: 0.7139 - val_loss: 0.6199 - val_acc: 0.6822
Epoch 3/25
84/84 - 4s - loss: 0.5795 - acc: 0.7123 - val_loss: 0.5800 - val_acc: 0.7205
Epoch 4/25
84/84 - 4s - loss: 0.5816 - acc: 0.7096 - val_loss: 0.5739 - val_acc: 0.7227
Epoch 5/25
84/84 - 4s - loss: 0.5811 - acc: 0.7114 - val_loss: 0.6003 - val_acc: 0.7198
Epoch 6/25
84/84 - 4s - loss: 0.5774 - acc: 0.7143 - val_loss: 0.5906 - val_acc: 0.7153
Epoch 7/25
84/84 - 4s - loss: 0.5764 - acc: 0.7176 - val_loss: 0.6150 - val_acc: 0.6807
Epoch 8/25
84/84 - 4s - loss: 0.5806 - acc: 0.7088 - val_loss: 0.5750 - val_acc: 0.7308
Epoch 9/25
84/84 - 4s - loss: 0.5741 - acc: 0.7146 - val_loss: 0.5868 - val_acc: 0.7227
Epoch 10/25
84/84 - 4s - loss: 0.5766 - acc: 0.7145 - val_loss: 0.5747 - val_acc: 0.7301
Epoch 11/25
84/84 - 4s - loss: 0.5767 - acc: 0.7117 - val_loss: 0.6028 - val_acc: 0.7050
Epoch 12/25
84/84 - 4s - loss: 0.5804 - acc: 0.7103 - val_loss: 0.5772 - val_acc: 0.7235
Epoch 13/25
84/84 - 5s - loss: 0.5744 - acc: 0.7158 - val_loss: 0.5764 - val_acc: 0.7301
Epoch 14/25
84/84 - 4s - loss: 0.5754 - acc: 0.7179 - val_loss: 0.5916 - val_acc: 0.7102
Epoch 15/25
84/84 - 4s - loss: 0.5752 - acc: 0.7155 - val_loss: 0.5748 - val_acc: 0.7271
Epoch 16/25
84/84 - 4s - loss: 0.5754 - acc: 0.7120 - val_loss: 0.5840 - val_acc: 0.7035
Epoch 17/25
84/84 - 4s - loss: 0.5795 - acc: 0.7099 - val_loss: 0.5743 - val_acc: 0.7316
Epoch 18/25
84/84 - 5s - loss: 0.5737 - acc: 0.7157 - val_loss: 0.5774 - val_acc: 0.7308
Epoch 19/25
84/84 - 5s - loss: 0.5737 - acc: 0.7158 - val_loss: 0.5821 - val_acc: 0.7257
Epoch 20/25
84/84 - 5s - loss: 0.5713 - acc: 0.7160 - val_loss: 0.5878 - val_acc: 0.7183
Epoch 21/25
84/84 - 4s - loss: 0.5744 - acc: 0.7136 - val_loss: 0.5817 - val_acc: 0.7249
Epoch 22/25
84/84 - 4s - loss: 0.5673 - acc: 0.7176 - val_loss: 0.6048 - val_acc: 0.7183
Epoch 23/25
84/84 - 4s - loss: 0.5735 - acc: 0.7187 - val_loss: 0.5852 - val_acc: 0.7286
Epoch 24/25
84/84 - 5s - loss: 0.5713 - acc: 0.7182 - val_loss: 0.6155 - val_acc: 0.6822
Epoch 25/25
84/84 - 5s - loss: 0.5758 - acc: 0.7094 - val_loss: 0.5701 - val_acc: 0.7345
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>

<span class="k">def</span> <span class="nf">plot_history</span><span class="p">(</span><span class="n">history</span><span class="p">):</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="nf">sorted</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">.</span><span class="nf">keys</span><span class="p">())</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="n">metrics</span><span class="p">[:</span><span class="nf">len</span><span class="p">(</span><span class="n">metrics</span><span class="p">)</span><span class="o">//</span><span class="mi">2</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">metrics</span><span class="p">:</span>
        <span class="c1"># summarize history for metric m
</span>        <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="n">m</span><span class="p">])</span>
        <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="sh">'</span><span class="s">val_</span><span class="sh">'</span> <span class="o">+</span> <span class="n">m</span><span class="p">])</span>
        <span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
        <span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
        <span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">epoch</span><span class="sh">'</span><span class="p">)</span>
        <span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">([</span><span class="sh">'</span><span class="s">train</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">test</span><span class="sh">'</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="sh">'</span><span class="s">best</span><span class="sh">'</span><span class="p">)</span>
        <span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">plot_history</span><span class="p">(</span><span class="n">history</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/img/Node_Prediction/output_44_0.png" alt="png" /></p>

<p><img src="/img/Node_Prediction/output_44_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">multiprocessing</span>
<span class="n">num_workers</span> <span class="o">=</span> <span class="n">multiprocessing</span><span class="p">.</span><span class="nf">cpu_count</span><span class="p">()</span><span class="o">//</span><span class="mi">2</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_metrics</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">evaluate_generator</span><span class="p">(</span><span class="n">train_gen</span><span class="p">,</span> <span class="n">use_multiprocessing</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">test_metrics</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">evaluate_generator</span><span class="p">(</span><span class="n">test_gen</span><span class="p">,</span> <span class="n">use_multiprocessing</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">Train Set Metrics of the trained model:</span><span class="sh">"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">metrics_names</span><span class="p">,</span> <span class="n">train_metrics</span><span class="p">):</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\t</span><span class="s">{}: {:0.4f}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">val</span><span class="p">))</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">Test Set Metrics of the trained model:</span><span class="sh">"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">metrics_names</span><span class="p">,</span> <span class="n">test_metrics</span><span class="p">):</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\t</span><span class="s">{}: {:0.4f}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">val</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>68/68 [==============================] - 1s 17ms/step - loss: 0.5598 - acc: 0.7303
17/17 [==============================] - 0s 22ms/step - loss: 0.5717 - acc: 0.7308

Train Set Metrics of the trained model:
	loss: 0.5598
	acc: 0.7303

Test Set Metrics of the trained model:
	loss: 0.5717
	acc: 0.7308
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">test_data</span><span class="p">[[</span><span class="sh">"</span><span class="s">conflict</span><span class="sh">"</span><span class="p">]])</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">predict_generator</span><span class="p">(</span><span class="n">test_gen</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="nf">classification_report</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">around</span><span class="p">(</span><span class="n">y_pred</span><span class="p">),</span> <span class="n">y_true</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>              precision    recall  f1-score   support

         0.0       0.84      0.74      0.79       920
         1.0       0.57      0.71      0.63       436

    accuracy                           0.73      1356
   macro avg       0.70      0.73      0.71      1356
weighted avg       0.75      0.73      0.74      1356
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test_metrics</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">evaluate_generator</span><span class="p">(</span><span class="n">test_gen</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">Test Set Metrics:</span><span class="sh">"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">metrics_names</span><span class="p">,</span> <span class="n">test_metrics</span><span class="p">):</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\t</span><span class="s">{}: {:0.4f}</span><span class="sh">"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">val</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Test Set Metrics:
	loss: 0.6371
	acc: 0.5906
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">precision_recall_fscore_support</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">precision_recall_fscore_support</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">test_data</span><span class="p">[</span><span class="sh">'</span><span class="s">depart</span><span class="sh">'</span><span class="p">]),</span> <span class="n">np</span><span class="p">.</span><span class="nf">around</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">predict_generator</span><span class="p">(</span><span class="n">generator</span><span class="p">.</span><span class="nf">flow</span><span class="p">(</span><span class="n">test_data</span><span class="p">[</span><span class="n">feature_names</span><span class="p">].</span><span class="n">index</span><span class="p">))),</span> <span class="n">average</span><span class="o">=</span><span class="sh">'</span><span class="s">macro</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(0.8549472020841564, 0.6859450510112762, 0.7364412336901534, None)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">precision_recall_fscore_support</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">test_data</span><span class="p">[</span><span class="sh">'</span><span class="s">depart</span><span class="sh">'</span><span class="p">]),</span> <span class="n">np</span><span class="p">.</span><span class="nf">around</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">predict_generator</span><span class="p">(</span><span class="n">generator</span><span class="p">.</span><span class="nf">flow</span><span class="p">(</span><span class="n">test_data</span><span class="p">[</span><span class="n">feature_names</span><span class="p">].</span><span class="n">index</span><span class="p">))),</span> <span class="n">average</span><span class="o">=</span><span class="sh">'</span><span class="s">micro</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(0.9210914454277286, 0.9210914454277286, 0.9210914454277286, None)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">precision_recall_fscore_support</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">test_data</span><span class="p">[</span><span class="sh">'</span><span class="s">depart</span><span class="sh">'</span><span class="p">]),</span> <span class="n">np</span><span class="p">.</span><span class="nf">around</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">predict_generator</span><span class="p">(</span><span class="n">generator</span><span class="p">.</span><span class="nf">flow</span><span class="p">(</span><span class="n">test_data</span><span class="p">[</span><span class="n">feature_names</span><span class="p">].</span><span class="n">index</span><span class="p">))),</span> <span class="n">average</span><span class="o">=</span><span class="sh">'</span><span class="s">weighted</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(0.9126711939188366, 0.9210914454277286, 0.909333076064201, None)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">num_tests</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1"># the number of times to generate predictions
</span><span class="n">all_test_predictions</span> <span class="o">=</span> <span class="p">[</span><span class="n">model</span><span class="p">.</span><span class="nf">predict_generator</span><span class="p">(</span><span class="n">test_gen</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">num_tests</span><span class="p">)]</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>17/17 [==============================] - 1s 51ms/step
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.calibration</span> <span class="kn">import</span> <span class="n">calibration_curve</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">calibration_data</span> <span class="o">=</span> <span class="p">[</span><span class="nf">calibration_curve</span><span class="p">(</span><span class="n">y_prob</span><span class="o">=</span><span class="n">test_predictions</span><span class="p">,</span> 
                                      <span class="n">y_true</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">test_data</span><span class="p">[</span><span class="sh">'</span><span class="s">depart</span><span class="sh">'</span><span class="p">]),</span> 
                                      <span class="n">n_bins</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> 
                                      <span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">test_predictions</span> <span class="ow">in</span> <span class="n">all_test_predictions</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">stellargraph</span> <span class="kn">import</span> <span class="n">expected_calibration_error</span><span class="p">,</span> <span class="n">plot_reliability_diagram</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">fraction_of_positives</span><span class="p">,</span> <span class="n">mean_predicted_value</span> <span class="ow">in</span> <span class="n">calibration_data</span><span class="p">:</span>
    <span class="n">ece_pre_calibration</span> <span class="o">=</span> <span class="nf">expected_calibration_error</span><span class="p">(</span><span class="n">prediction_probabilities</span><span class="o">=</span><span class="n">all_test_predictions</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> 
                                                     <span class="n">accuracy</span><span class="o">=</span><span class="n">fraction_of_positives</span><span class="p">,</span> 
                                                     <span class="n">confidence</span><span class="o">=</span><span class="n">mean_predicted_value</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">ECE: (before calibration) {:.4f}</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">ece_pre_calibration</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ECE: (before calibration) 0.0211
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">plot_reliability_diagram</span><span class="p">(</span><span class="n">calibration_data</span><span class="p">,</span> 
                         <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">all_test_predictions</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> 
                         <span class="n">ece</span><span class="o">=</span><span class="p">[</span><span class="n">ece_pre_calibration</span><span class="p">])</span>
</code></pre></div></div>

<p><img src="/img/Node_Prediction/output_61_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">use_platt</span> <span class="o">=</span> <span class="bp">False</span>  <span class="c1"># True for Platt scaling or False for Isotonic Regression
</span><span class="n">num_tests</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">score_model</span> <span class="o">=</span> <span class="nc">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">x_inp</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">prediction</span><span class="p">)</span>
<span class="k">if</span> <span class="n">use_platt</span><span class="p">:</span>
    <span class="n">all_test_score_predictions</span> <span class="o">=</span> <span class="p">[</span><span class="n">score_model</span><span class="p">.</span><span class="nf">predict_generator</span><span class="p">(</span><span class="n">test_gen</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">num_tests</span><span class="p">)]</span>
    <span class="n">all_test_probabilistic_predictions</span> <span class="o">=</span> <span class="p">[</span><span class="n">model</span><span class="p">.</span><span class="nf">predict_generator</span><span class="p">(</span><span class="n">test_gen</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">num_tests</span><span class="p">)]</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">all_test_probabilistic_predictions</span> <span class="o">=</span> <span class="p">[</span><span class="n">model</span><span class="p">.</span><span class="nf">predict_generator</span><span class="p">(</span><span class="n">test_gen</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">num_tests</span><span class="p">)]</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>17/17 [==============================] - 1s 57ms/step
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># These are the uncalibrated prediction probabilities. 
</span><span class="k">if</span> <span class="n">use_platt</span><span class="p">:</span>
    <span class="n">test_predictions</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">all_test_score_predictions</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">test_predictions</span><span class="p">.</span><span class="n">shape</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">test_predictions</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">all_test_probabilistic_predictions</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">test_predictions</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">stellargraph</span> <span class="kn">import</span> <span class="n">IsotonicCalibration</span><span class="p">,</span> <span class="n">TemperatureCalibration</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">if</span> <span class="n">use_platt</span><span class="p">:</span>
    <span class="c1"># for binary classification this class performs Platt Scaling
</span>    <span class="n">lr</span> <span class="o">=</span> <span class="nc">TemperatureCalibration</span><span class="p">()</span>  
<span class="k">else</span><span class="p">:</span>
    <span class="n">lr</span> <span class="o">=</span> <span class="nc">IsotonicCalibration</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lr</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">test_predictions</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">test_data</span><span class="p">[</span><span class="sh">'</span><span class="s">depart</span><span class="sh">'</span><span class="p">]))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lr_test_predictions</span> <span class="o">=</span> <span class="n">lr</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">test_predictions</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">calibration_data</span> <span class="o">=</span> <span class="p">[</span><span class="nf">calibration_curve</span><span class="p">(</span><span class="n">y_prob</span><span class="o">=</span><span class="n">lr_test_predictions</span><span class="p">,</span> 
                                      <span class="n">y_true</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">test_data</span><span class="p">[</span><span class="sh">'</span><span class="s">depart</span><span class="sh">'</span><span class="p">]),</span> 
                                      <span class="n">n_bins</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> 
                                      <span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">)]</span> 
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">fraction_of_positives</span><span class="p">,</span> <span class="n">mean_predicted_value</span> <span class="ow">in</span> <span class="n">calibration_data</span><span class="p">:</span>
    <span class="n">ece_post_calibration</span> <span class="o">=</span> <span class="nf">expected_calibration_error</span><span class="p">(</span><span class="n">prediction_probabilities</span><span class="o">=</span><span class="n">lr_test_predictions</span><span class="p">,</span> 
                                                      <span class="n">accuracy</span><span class="o">=</span><span class="n">fraction_of_positives</span><span class="p">,</span> 
                                                      <span class="n">confidence</span><span class="o">=</span><span class="n">mean_predicted_value</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">ECE (after calibration): {:.4f}</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">ece_post_calibration</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ECE (after calibration): 0.0000
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">plot_reliability_diagram</span><span class="p">(</span><span class="n">calibration_data</span><span class="p">,</span> 
                         <span class="n">lr_test_predictions</span><span class="p">,</span> 
                         <span class="n">ece</span><span class="o">=</span><span class="p">[</span><span class="n">ece_post_calibration</span><span class="p">])</span>
</code></pre></div></div>

<p><img src="/img/Node_Prediction/output_70_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">test_predictions</span><span class="p">))</span>
<span class="k">if</span> <span class="n">use_platt</span><span class="p">:</span>
    <span class="c1"># the true predictions are the probabilistic outputs
</span>    <span class="n">test_predictions</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">all_test_probabilistic_predictions</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">y_pred</span><span class="p">[</span><span class="n">test_predictions</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">&gt;</span><span class="mf">0.5</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Accuracy of model before calibration: {:.2f}</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="nf">accuracy_score</span><span class="p">(</span><span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">,</span> 
                                                                           <span class="n">y_true</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">test_data</span><span class="p">[</span><span class="sh">'</span><span class="s">depart</span><span class="sh">'</span><span class="p">]))))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Accuracy of model before calibration: 0.92
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">lr_test_predictions</span><span class="p">))</span>
<span class="n">y_pred</span><span class="p">[</span><span class="n">lr_test_predictions</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">&gt;</span><span class="mf">0.5</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Accuracy for model after calibration: {:.2f}</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="nf">accuracy_score</span><span class="p">(</span><span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_true</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">test_data</span><span class="p">[</span><span class="sh">'</span><span class="s">depart</span><span class="sh">'</span><span class="p">]))))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Accuracy for model after calibration: 0.92
</code></pre></div></div>

<p>Find impotant features</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">big_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">"</span><span class="s">data/big_df_orig.csv</span><span class="sh">"</span><span class="p">)</span>
<span class="n">big_df</span><span class="p">.</span><span class="nf">drop</span><span class="p">([</span><span class="sh">'</span><span class="s">Unnamed: 0</span><span class="sh">'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">big_df</span><span class="p">[</span><span class="sh">'</span><span class="s">Count</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">big_df</span><span class="p">[</span><span class="sh">'</span><span class="s">Count</span><span class="sh">'</span><span class="p">]</span><span class="o">-</span><span class="n">big_df</span><span class="p">[</span><span class="sh">'</span><span class="s">Count</span><span class="sh">'</span><span class="p">].</span><span class="nf">mean</span><span class="p">())</span><span class="o">/</span><span class="n">big_df</span><span class="p">[</span><span class="sh">'</span><span class="s">Count</span><span class="sh">'</span><span class="p">].</span><span class="nf">std</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">big_df</span><span class="p">.</span><span class="n">columns</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Index(['node', 'deg', 'close', 'between', 'eigen', 'Count', 'depart'], dtype='object')
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">model_selection</span><span class="p">.</span><span class="nf">train_test_split</span><span class="p">(</span><span class="n">big_df</span><span class="p">[[</span><span class="sh">'</span><span class="s">between</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Count</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">deg</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">close</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">eigen</span><span class="sh">'</span><span class="p">]],</span> <span class="n">big_df</span><span class="p">[</span><span class="sh">'</span><span class="s">depart</span><span class="sh">'</span><span class="p">],</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">)</span>
<span class="n">n_train</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">.</span><span class="n">shape</span>
<span class="nf">print</span><span class="p">(</span><span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X_test</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(5424, 5) (1356, 5)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">n</span><span class="p">,</span> <span class="n">d</span> <span class="o">=</span> <span class="n">big_df</span><span class="p">[[</span><span class="sh">'</span><span class="s">between</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Count</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">deg</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">close</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">eigen</span><span class="sh">'</span><span class="p">]].</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">big_df</span><span class="p">[</span><span class="n">big_df</span><span class="p">[</span><span class="sh">'</span><span class="s">depart</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">][</span><span class="sh">'</span><span class="s">between</span><span class="sh">'</span><span class="p">].</span><span class="nf">describe</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>count    6039.000000
mean        0.001111
std         0.011457
min         0.000000
25%         0.000000
50%         0.000000
75%         0.000038
max         0.573032
Name: between, dtype: float64
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">big_df</span><span class="p">[</span><span class="n">big_df</span><span class="p">[</span><span class="sh">'</span><span class="s">depart</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">][</span><span class="sh">'</span><span class="s">between</span><span class="sh">'</span><span class="p">].</span><span class="nf">describe</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>count    741.000000
mean       0.000131
std        0.000813
min        0.000000
25%        0.000000
50%        0.000000
75%        0.000000
max        0.016785
Name: between, dtype: float64
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Create Correlation df
</span><span class="n">corr</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">.</span><span class="nf">corr</span><span class="p">()</span>
<span class="c1">#Plot figsize
</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="c1">#Generate Color Map
</span><span class="n">colormap</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="nf">diverging_palette</span><span class="p">(</span><span class="mi">220</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">as_cmap</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c1">#Generate Heat Map, allow annotations and place floats in map
</span><span class="n">sns</span><span class="p">.</span><span class="nf">heatmap</span><span class="p">(</span><span class="n">corr</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">colormap</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="sh">"</span><span class="s">.2f</span><span class="sh">"</span><span class="p">)</span>
<span class="c1">#Apply xticks
</span><span class="n">plt</span><span class="p">.</span><span class="nf">xticks</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">corr</span><span class="p">.</span><span class="n">columns</span><span class="p">)),</span> <span class="n">corr</span><span class="p">.</span><span class="n">columns</span><span class="p">);</span>
<span class="c1">#Apply yticks
</span><span class="n">plt</span><span class="p">.</span><span class="nf">yticks</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">corr</span><span class="p">.</span><span class="n">columns</span><span class="p">)),</span> <span class="n">corr</span><span class="p">.</span><span class="n">columns</span><span class="p">)</span>
<span class="c1">#show plot
</span><span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/img/Node_Prediction/output_86_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sns</span><span class="p">.</span><span class="nf">pairplot</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/img/Node_Prediction/output_87_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">COV</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">cov</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">matshow</span><span class="p">(</span><span class="n">COV</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/img/Node_Prediction/output_88_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">U</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="nf">svd</span><span class="p">(</span><span class="n">COV</span><span class="p">,</span> <span class="n">full_matrices</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="sh">'</span><span class="s">r-o</span><span class="sh">'</span><span class="p">)</span>
<span class="c1">#plt.axvline(60, c='r')
</span><span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">"</span><span class="s">Valeurs singulires de la matrice de corrlation</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/img/Node_Prediction/output_90_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">s</span> <span class="o">&lt;</span> <span class="mf">0.01</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([False,  True,  True,  True,  True])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">len</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>5
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">s</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([1.00154518e+00, 7.86947491e-04, 1.36366655e-04, 1.23305685e-04,
       1.58050399e-07])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span><span class="p">,</span> <span class="n">Ridge</span><span class="p">,</span> <span class="n">LassoCV</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">regr0</span> <span class="o">=</span> <span class="nc">LinearRegression</span><span class="p">()</span>
<span class="n">regr0</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">regr0</span><span class="p">.</span><span class="n">coef_</span><span class="p">,</span> <span class="sh">'</span><span class="s">r-o</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">"</span><span class="s">Valeurs des coefficients OLS</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/img/Node_Prediction/output_95_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">regr0</span><span class="p">.</span><span class="n">coef_</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([-2.25750655e-01,  2.61360005e-02,  7.06336051e+01,  4.24735688e-01,
       -5.19505034e-02])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_train_reduce</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">U</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">])</span>
<span class="n">X_test_reduce</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">dot</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">U</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">])</span>

<span class="n">regr1</span> <span class="o">=</span> <span class="nc">LinearRegression</span><span class="p">()</span>
<span class="n">regr1</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train_reduce</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">regr1</span><span class="p">.</span><span class="n">coef_</span><span class="p">,</span> <span class="sh">'</span><span class="s">r-o</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">"</span><span class="s">Valeurs des coefficients de PCA_before_OLS (sans intercept)</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/img/Node_Prediction/output_97_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="p">(</span><span class="n">regr0</span><span class="p">.</span><span class="n">intercept_</span><span class="p">,</span> <span class="n">regr1</span><span class="p">.</span><span class="n">intercept_</span><span class="p">,</span> <span class="n">y_train</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)):</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">%.3f</span><span class="sh">"</span> <span class="o">%</span> <span class="n">y</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="se">\n</span><span class="s">Les deux intercepts sont-ils gaux: %s</span><span class="sh">"</span>
      <span class="o">%</span> <span class="n">np</span><span class="p">.</span><span class="nf">isclose</span><span class="p">(</span><span class="n">regr0</span><span class="p">.</span><span class="n">intercept_</span><span class="p">,</span> <span class="n">regr1</span><span class="p">.</span><span class="n">intercept_</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0.822
0.808
0.893

Les deux intercepts sont-ils gaux: False
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn</span> <span class="kn">import</span> <span class="n">preprocessing</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_train_reduce2</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="p">.</span><span class="nf">scale</span><span class="p">(</span><span class="n">X_train_reduce</span><span class="p">)</span>

<span class="n">regrtest</span> <span class="o">=</span> <span class="nc">LinearRegression</span><span class="p">()</span>
<span class="n">regrtest</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train_reduce2</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">On vrifie l</span><span class="sh">'</span><span class="s">galit. Cette galit est: %s.</span><span class="sh">"</span>
      <span class="o">%</span> <span class="n">np</span><span class="p">.</span><span class="nf">isclose</span><span class="p">(</span><span class="n">regrtest</span><span class="p">.</span><span class="n">intercept_</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">y_train</span><span class="p">)))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>On vrifie l'galit. Cette galit est: True.
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">R20</span> <span class="o">=</span> <span class="n">regr0</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> 
<span class="n">R21</span> <span class="o">=</span> <span class="n">regr1</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="n">X_test_reduce</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">MSE</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_true</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">((</span><span class="n">y_pred</span> <span class="o">-</span> <span class="n">y_true</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">pred_error0</span> <span class="o">=</span> <span class="nc">MSE</span><span class="p">(</span><span class="n">regr0</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="n">y_test</span><span class="p">)</span>
<span class="n">pred_error1</span> <span class="o">=</span> <span class="nc">MSE</span><span class="p">(</span><span class="n">regr1</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test_reduce</span><span class="p">),</span> <span class="n">y_test</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Le R2 de OLS:            %.3f</span><span class="sh">"</span> <span class="o">%</span> <span class="n">R20</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Le R2 de PCA before OLS: %.3f</span><span class="se">\n</span><span class="sh">"</span> <span class="o">%</span> <span class="n">R21</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Le rique de prdiction de OLS calcul sur l</span><span class="sh">'</span><span class="s">chantillon test:            %.2f</span><span class="sh">"</span> <span class="o">%</span> <span class="n">pred_error0</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Le rique de prdiction de PCA before OLS calcul sur l</span><span class="sh">'</span><span class="s">chantillon test: %.2f</span><span class="sh">"</span> <span class="o">%</span> <span class="n">pred_error1</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Le R2 de OLS:            0.018
Le R2 de PCA before OLS: 0.008

Le rique de prdiction de OLS calcul sur l'chantillon test:            0.10
Le rique de prdiction de PCA before OLS calcul sur l'chantillon test: 0.10
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">eps0</span> <span class="o">=</span> <span class="n">regr0</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span> <span class="o">-</span> <span class="n">y_test</span>
<span class="n">eps1</span> <span class="o">=</span> <span class="n">regr1</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test_reduce</span><span class="p">)</span> <span class="o">-</span> <span class="n">y_test</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">eps0</span><span class="p">.</span><span class="n">values</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">ols</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">eps1</span><span class="p">.</span><span class="n">values</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">pca_before_ols</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">"</span><span class="s">Visualisation des rsidus</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/img/Node_Prediction/output_102_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">eps</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">c_</span><span class="p">[</span><span class="n">eps0</span><span class="p">,</span> <span class="n">eps1</span><span class="p">],</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">OLS</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">PCA_before_OLS</span><span class="sh">'</span><span class="p">])</span>
<span class="n">eps</span><span class="p">.</span><span class="nf">hist</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/img/Node_Prediction/output_103_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">resids</span> <span class="o">=</span> <span class="n">y_train</span>

<span class="n">test</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">d</span><span class="p">,</span> <span class="n">d</span><span class="p">))</span>
<span class="n">pval_mem</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
<span class="n">pval</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">d</span><span class="p">,</span> <span class="n">d</span><span class="p">))</span>
<span class="n">var_sel</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">var_remain</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">between</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Count</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">deg</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">close</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">eigen</span><span class="sh">'</span><span class="p">]</span> <span class="c1">#list(range(d))
</span><span class="n">in_test</span> <span class="o">=</span> <span class="p">[]</span>
 
<span class="n">regr</span> <span class="o">=</span> <span class="nc">LinearRegression</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">scipy.stats</span> <span class="kn">import</span> <span class="n">norm</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">d</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>5
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">d</span><span class="p">):</span> 
    <span class="n">resids_mem</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">d</span><span class="p">,</span> <span class="n">n_train</span><span class="p">))</span>
    <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">var_remain</span><span class="p">:</span>
        <span class="n">xtmp</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="nf">list</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span> <span class="c1">#X_train[:, [i]]
</span>        <span class="n">xtmp</span> <span class="o">=</span> <span class="n">xtmp</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">regr</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">xtmp</span><span class="p">,</span> <span class="n">resids</span><span class="p">)</span>
        
        <span class="c1"># calcul de (x'x)
</span>        <span class="n">xx</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="c1">#xx = np.sum(X_train[:, i] ** 2)
</span>        <span class="n">resids_mem</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">regr</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">xtmp</span><span class="p">)</span> <span class="o">-</span> <span class="n">resids</span>
        <span class="n">sigma2_tmp</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">resids_mem</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="p">:]</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">xx</span>
        <span class="n">test</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nf">abs</span><span class="p">(</span><span class="n">regr</span><span class="p">.</span><span class="n">coef_</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">sigma2_tmp</span><span class="p">))</span>
        <span class="n">pval</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">norm</span><span class="p">.</span><span class="nf">cdf</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">j</span><span class="p">]))</span>
        <span class="n">j</span> <span class="o">=</span> <span class="n">j</span> <span class="o">+</span> <span class="mi">1</span>

    <span class="c1"># separe en deux vecteurs la listes des variables slctionnes et les autres
</span>    <span class="n">best_var</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="p">:])</span>
    <span class="n">var_sel</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">best_var</span><span class="p">)</span>
    <span class="n">resids</span> <span class="o">=</span> <span class="n">resids_mem</span><span class="p">[</span><span class="n">best_var</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">pval_mem</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">pval</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">best_var</span><span class="p">]</span>
    <span class="n">var_remain</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">setdiff1d</span><span class="p">(</span><span class="n">var_remain</span><span class="p">,</span> <span class="n">var_sel</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Voici l</span><span class="sh">'</span><span class="s">ordre dans lequel les variables sont slectiones par la mthode forward :</span><span class="se">\n\n</span><span class="s">%s</span><span class="sh">"</span> <span class="o">%</span> <span class="n">var_sel</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Voici l'ordre dans lequel les variables sont slectiones par la mthode forward :

[3, 3, 2, 0, 3]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">()</span>

<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    
    <span class="n">plt</span><span class="p">.</span><span class="nf">subplot</span><span class="p">(</span><span class="mi">311</span> <span class="o">+</span> <span class="n">k</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">k</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">"</span><span class="s">values of the t-stat at each step</span><span class="sh">"</span><span class="p">)</span>

    <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">d</span><span class="p">),</span> <span class="n">test</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="p">:],</span> <span class="sh">'</span><span class="s">-o</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">step %s</span><span class="sh">"</span> <span class="o">%</span> <span class="n">k</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">var_sel</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">test</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">var_sel</span><span class="p">[</span><span class="n">k</span><span class="p">]],</span> <span class="sh">'</span><span class="s">r-o</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">k</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">features</span><span class="sh">"</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/img/Node_Prediction/output_108_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig2</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">()</span>

<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span> 
    <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">d</span><span class="p">),</span> <span class="n">pval_mem</span><span class="p">,</span> <span class="sh">'</span><span class="s">o</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="p">[.</span><span class="mi">1</span><span class="p">,</span> <span class="p">.</span><span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="sh">"</span><span class="s">b</span><span class="sh">"</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="nf">axis</span><span class="p">(</span><span class="n">xmin</span><span class="o">=-</span><span class="p">.</span><span class="mi">5</span><span class="p">,</span> <span class="n">xmax</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">ymin</span><span class="o">=-</span><span class="p">.</span><span class="mi">03</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">"</span><span class="s">Graph des p-valeurs</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">steps</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/img/Node_Prediction/output_109_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">var_sel_a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">var_sel</span><span class="p">)</span>
<span class="c1">#print(var_sel_a,var_sel)
</span><span class="n">var_sel_def</span> <span class="o">=</span> <span class="n">var_sel_a</span><span class="p">[</span><span class="n">pval_mem</span> <span class="o">&lt;</span> <span class="mf">0.001</span><span class="p">]</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Il y a donc %s variables selectionnes.</span><span class="se">\n</span><span class="s">Les voici: %s</span><span class="sh">"</span> <span class="o">%</span> <span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">var_sel_def</span><span class="p">),</span> <span class="n">var_sel_def</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>There are therefore 4 selected variables.
Here they are: [3 3 2 0]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_train</span><span class="p">.</span><span class="n">columns</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Index(['between', 'Count', 'deg', 'close', 'eigen'], dtype='object')
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_train_sel</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[[</span><span class="sh">'</span><span class="s">between</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Count</span><span class="sh">'</span><span class="p">]]</span>
<span class="n">X_test_sel</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">[[</span><span class="sh">'</span><span class="s">between</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Count</span><span class="sh">'</span><span class="p">]]</span>

<span class="n">regr2</span> <span class="o">=</span> <span class="nc">LinearRegression</span><span class="p">()</span>
<span class="n">regr2</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train_sel</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="n">regr2</span><span class="p">.</span><span class="n">coef_</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">regr2</span><span class="p">.</span><span class="n">intercept_</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[0.89524856 0.0158369 ]
0.8918800888752971
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pred_error_forward</span> <span class="o">=</span> <span class="nc">MSE</span><span class="p">(</span><span class="n">regr2</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test_sel</span><span class="p">),</span> <span class="n">y_test</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">As a reminder, let us give the prediction scores obtained previouslyt.</span><span class="se">\n</span><span class="sh">"</span><span class="p">)</span>

<span class="k">for</span> <span class="n">method</span><span class="p">,</span> <span class="n">error</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">([</span><span class="sh">"</span><span class="s">ols           </span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">pca_before_ols</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">forward       </span><span class="sh">"</span><span class="p">],</span>
                         <span class="p">[</span><span class="n">pred_error0</span><span class="p">,</span> <span class="n">pred_error1</span><span class="p">,</span> <span class="n">pred_error_forward</span><span class="p">]):</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">method</span> <span class="o">+</span> <span class="sh">"</span><span class="s"> : %.2f</span><span class="sh">"</span> <span class="o">%</span> <span class="n">error</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>As a reminder, let us give the prediction scores obtained previouslyt.

ols            : 0.10
pca_before_ols : 0.10
forward        : 0.10
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">seed</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">perm</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">permutation</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="n">n_train</span><span class="p">))</span>
<span class="n">q</span> <span class="o">=</span> <span class="n">n_train</span> <span class="o">/</span> <span class="mf">4.</span>
<span class="n">split</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span> <span class="o">*</span> <span class="n">q</span>
<span class="n">split</span> <span class="o">=</span> <span class="n">split</span><span class="p">.</span><span class="nf">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

<span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">The fold %s contains:</span><span class="se">\n</span><span class="s">%s</span><span class="se">\n\n</span><span class="sh">"</span> <span class="o">%</span> <span class="p">(</span><span class="n">fold</span><span class="p">,</span> <span class="n">perm</span><span class="p">[</span><span class="n">split</span><span class="p">[</span><span class="n">fold</span><span class="p">]:</span> <span class="n">split</span><span class="p">[</span><span class="n">fold</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]]))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>The fold 0 contains:
[2486  738 4875 ... 3688 3723 1036]


The fold 1 containst:
[2491  857 3734 ... 4839 1668 2992]


The fold 2 contains:
[2659 1106 5196 ... 4191 3589 4707]


The fold 3 contains:
[5070 2885  249 ... 2514 3606 2575]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lasso</span> <span class="o">=</span> <span class="nc">LassoCV</span><span class="p">()</span>
<span class="n">lasso</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># The estimator chose automatically its lambda:
</span><span class="n">lasso</span><span class="p">.</span><span class="n">alpha_</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2.1532196265600495e-05
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pred_error_lasso</span> <span class="o">=</span> <span class="nc">MSE</span><span class="p">(</span><span class="n">lasso</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="n">y_test</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">As a reminder, let</span><span class="sh">'</span><span class="s">s give the scores obtained previously.</span><span class="se">\n</span><span class="sh">"</span><span class="p">)</span>

<span class="k">for</span> <span class="n">method</span><span class="p">,</span> <span class="n">error</span> <span class="ow">in</span> <span class="nf">zip</span><span class="p">([</span><span class="sh">"</span><span class="s">ols           </span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">pca_before_ols</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">forward       </span><span class="sh">"</span><span class="p">,</span>
                          <span class="sh">"</span><span class="s">lasso         </span><span class="sh">"</span><span class="p">],</span>
                         <span class="p">[</span><span class="n">pred_error0</span><span class="p">,</span> <span class="n">pred_error1</span><span class="p">,</span> <span class="n">pred_error_forward</span><span class="p">,</span>
                           <span class="n">pred_error_lasso</span><span class="p">]):</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">method</span> <span class="o">+</span> <span class="sh">"</span><span class="s"> : %.2f</span><span class="sh">"</span> <span class="o">%</span> <span class="n">error</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>As a reminder, let's give the scores obtained previously.

ols            : 0.10
pca_before_ols : 0.10
forward        : 0.10
lasso          : 0.10
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="n">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">SelectKBest</span>
<span class="kn">from</span> <span class="n">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">chi2</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">big_df</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">big_df_</span> <span class="o">=</span> <span class="n">big_df</span>
<span class="n">big_df_</span><span class="p">[[</span><span class="sh">'</span><span class="s">deg</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">close</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">between</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">eigen</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Count</span><span class="sh">'</span><span class="p">]]</span> <span class="o">=</span> <span class="n">big_df_</span><span class="p">[[</span><span class="sh">'</span><span class="s">deg</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">close</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">between</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">eigen</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Count</span><span class="sh">'</span><span class="p">]]</span><span class="o">*</span><span class="mi">1000</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">big_df_</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">big_df</span><span class="p">.</span><span class="n">columns</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Index(['deg', 'close', 'between', 'eigen', 'Count', 'depart'], dtype='object')
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X</span> <span class="o">=</span> <span class="n">big_df</span><span class="p">[[</span><span class="sh">'</span><span class="s">deg</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">close</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">between</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">eigen</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Count</span><span class="sh">'</span><span class="p">]]</span>  <span class="c1">#independent columns
</span><span class="n">y</span> <span class="o">=</span> <span class="n">big_df</span><span class="p">[[</span><span class="sh">'</span><span class="s">depart</span><span class="sh">'</span><span class="p">]]</span>    <span class="c1">#target column i.e price range
</span><span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">ExtraTreesClassifier</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">model</span> <span class="o">=</span> <span class="nc">ExtraTreesClassifier</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">feature_importances_</span><span class="p">)</span> <span class="c1">#use inbuilt class feature_importances of tree based classifiers
#plot graph of feature importances for better visualization
</span><span class="n">feat_importances</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">Series</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">feature_importances_</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">X</span><span class="p">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">feat_importances</span><span class="p">.</span><span class="nf">nlargest</span><span class="p">(</span><span class="mi">5</span><span class="p">).</span><span class="nf">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="sh">'</span><span class="s">barh</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[0.02971642 0.32936866 0.03982511 0.1503454  0.45074441]


/home/arij/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.
  "10 in version 0.20 to 100 in 0.22.", FutureWarning)
/home/arij/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
</code></pre></div></div>

<p><img src="/img/Node_Prediction/output_124_2.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X</span> <span class="o">=</span> <span class="n">big_df_</span><span class="p">[[</span><span class="sh">'</span><span class="s">deg</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">close</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">between</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">eigen</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Count</span><span class="sh">'</span><span class="p">]]</span>  <span class="c1">#independent columns
</span><span class="n">y</span> <span class="o">=</span> <span class="n">big_df_</span><span class="p">[[</span><span class="sh">'</span><span class="s">depart</span><span class="sh">'</span><span class="p">]]</span>    <span class="c1">#target column i.e price range
</span><span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">ExtraTreesClassifier</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">model</span> <span class="o">=</span> <span class="nc">ExtraTreesClassifier</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">feature_importances_</span><span class="p">)</span> <span class="c1">#use inbuilt class feature_importances of tree based classifiers
#plot graph of feature importances for better visualization
</span><span class="n">feat_importances</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">Series</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">feature_importances_</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">X</span><span class="p">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">feat_importances</span><span class="p">.</span><span class="nf">nlargest</span><span class="p">(</span><span class="mi">5</span><span class="p">).</span><span class="nf">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="sh">'</span><span class="s">barh</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[0.02684944 0.29080116 0.03635093 0.21448593 0.43151254]
</code></pre></div></div>

<p><img src="/img/Node_Prediction/output_124_2.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">statsmodels.api</span> <span class="k">as</span> <span class="n">sm</span>
<span class="kn">from</span> <span class="n">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">RFE</span>
<span class="kn">from</span> <span class="n">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">RidgeCV</span><span class="p">,</span> <span class="n">LassoCV</span><span class="p">,</span> <span class="n">Ridge</span><span class="p">,</span> <span class="n">Lasso</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">big_df</span><span class="p">.</span><span class="n">columns</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Index(['node', 'deg', 'close', 'between', 'eigen', 'Count', 'depart'], dtype='object')
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Adding constant column of ones, mandatory for sm.OLS model
</span><span class="n">X_1</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="nf">add_constant</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="c1">#Fitting sm.OLS model
</span><span class="n">model</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="nc">OLS</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">X_1</span><span class="p">).</span><span class="nf">fit</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="n">pvalues</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>const      0.000000e+00
deg        1.460348e-13
close      9.604029e-04
between    5.430823e-01
eigen      7.315541e-01
Count      1.949169e-10
dtype: float64
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Backward Elimination
</span><span class="n">cols</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">pmax</span> <span class="o">=</span> <span class="mi">1</span>
<span class="nf">while </span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">cols</span><span class="p">)</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">):</span>
    <span class="n">p</span><span class="o">=</span> <span class="p">[]</span>
    <span class="n">X_1</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">cols</span><span class="p">]</span>
    <span class="n">X_1</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="nf">add_constant</span><span class="p">(</span><span class="n">X_1</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="nc">OLS</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">X_1</span><span class="p">).</span><span class="nf">fit</span><span class="p">()</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">Series</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">pvalues</span><span class="p">.</span><span class="n">values</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span><span class="n">index</span> <span class="o">=</span> <span class="n">cols</span><span class="p">)</span>      
    <span class="n">pmax</span> <span class="o">=</span> <span class="nf">max</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
    <span class="n">feature_with_p_max</span> <span class="o">=</span> <span class="n">p</span><span class="p">.</span><span class="nf">idxmax</span><span class="p">()</span>
    <span class="nf">if</span><span class="p">(</span><span class="n">pmax</span><span class="o">&gt;</span><span class="mf">0.05</span><span class="p">):</span>
        <span class="n">cols</span><span class="p">.</span><span class="nf">remove</span><span class="p">(</span><span class="n">feature_with_p_max</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">break</span>
<span class="n">selected_features_BE</span> <span class="o">=</span> <span class="n">cols</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="n">selected_features_BE</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>['deg', 'close', 'Count']
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="nc">LinearRegression</span><span class="p">()</span>
<span class="c1">#Initializing RFE model
</span><span class="n">rfe</span> <span class="o">=</span> <span class="nc">RFE</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="c1">#Transforming data using RFE
</span><span class="n">X_rfe</span> <span class="o">=</span> <span class="n">rfe</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>  
<span class="c1">#Fitting the data to model
</span><span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_rfe</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">rfe</span><span class="p">.</span><span class="n">support_</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">rfe</span><span class="p">.</span><span class="n">ranking_</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[ True  True  True  True  True]
[1 1 1 1 1]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#no of features
</span><span class="n">nof_list</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">13</span><span class="p">)</span>            
<span class="n">high_score</span><span class="o">=</span><span class="mi">0</span>
<span class="c1">#Variable to store the optimum features
</span><span class="n">nof</span><span class="o">=</span><span class="mi">0</span>           
<span class="n">score_list</span> <span class="o">=</span><span class="p">[]</span>
<span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">nof_list</span><span class="p">)):</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">model_selection</span><span class="p">.</span><span class="nf">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="nc">LinearRegression</span><span class="p">()</span>
    <span class="n">rfe</span> <span class="o">=</span> <span class="nc">RFE</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">nof_list</span><span class="p">[</span><span class="n">n</span><span class="p">])</span>
    <span class="n">X_train_rfe</span> <span class="o">=</span> <span class="n">rfe</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
    <span class="n">X_test_rfe</span> <span class="o">=</span> <span class="n">rfe</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train_rfe</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="n">X_test_rfe</span><span class="p">,</span><span class="n">y_test</span><span class="p">)</span>
    <span class="n">score_list</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
    <span class="nf">if</span><span class="p">(</span><span class="n">score</span><span class="o">&gt;</span><span class="n">high_score</span><span class="p">):</span>
        <span class="n">high_score</span> <span class="o">=</span> <span class="n">score</span>
        <span class="n">nof</span> <span class="o">=</span> <span class="n">nof_list</span><span class="p">[</span><span class="n">n</span><span class="p">]</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Optimum number of features: %d</span><span class="sh">"</span> <span class="o">%</span><span class="n">nof</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Score with %d features: %f</span><span class="sh">"</span> <span class="o">%</span> <span class="p">(</span><span class="n">nof</span><span class="p">,</span> <span class="n">high_score</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Optimum number of features: 1
Score with 1 features: 0.005617
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cols</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="nc">LinearRegression</span><span class="p">()</span>
<span class="c1">#Initializing RFE model
</span><span class="n">rfe</span> <span class="o">=</span> <span class="nc">RFE</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>             
<span class="c1">#Transforming data using RFE
</span><span class="n">X_rfe</span> <span class="o">=</span> <span class="n">rfe</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>  
<span class="c1">#Fitting the data to model
</span><span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_rfe</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>              
<span class="n">temp</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">Series</span><span class="p">(</span><span class="n">rfe</span><span class="p">.</span><span class="n">support_</span><span class="p">,</span><span class="n">index</span> <span class="o">=</span> <span class="n">cols</span><span class="p">)</span>
<span class="n">selected_features_rfe</span> <span class="o">=</span> <span class="n">temp</span><span class="p">[</span><span class="n">temp</span><span class="o">==</span><span class="bp">True</span><span class="p">].</span><span class="n">index</span>
<span class="nf">print</span><span class="p">(</span><span class="n">selected_features_rfe</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Index(['deg'], dtype='object')
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">reg</span> <span class="o">=</span> <span class="nc">LassoCV</span><span class="p">()</span>
<span class="n">reg</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Best alpha using built-in LassoCV: %f</span><span class="sh">"</span> <span class="o">%</span> <span class="n">reg</span><span class="p">.</span><span class="n">alpha_</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Best score using built-in LassoCV: %f</span><span class="sh">"</span> <span class="o">%</span><span class="n">reg</span><span class="p">.</span><span class="nf">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">))</span>
<span class="n">coef</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">Series</span><span class="p">(</span><span class="n">reg</span><span class="p">.</span><span class="n">coef_</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">columns</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Best alpha using built-in LassoCV: 0.000040
Best score using built-in LassoCV: 0.009326
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Lasso picked </span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="nf">sum</span><span class="p">(</span><span class="n">coef</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">))</span> <span class="o">+</span> <span class="sh">"</span><span class="s"> variables and eliminated the other </span><span class="sh">"</span> <span class="o">+</span>  <span class="nf">str</span><span class="p">(</span><span class="nf">sum</span><span class="p">(</span><span class="n">coef</span> <span class="o">==</span> <span class="mi">0</span><span class="p">))</span> <span class="o">+</span> <span class="sh">"</span><span class="s"> variables</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Lasso picked 4 variables and eliminated the other 1 variables
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">imp_coef</span> <span class="o">=</span> <span class="n">coef</span><span class="p">.</span><span class="nf">sort_values</span><span class="p">()</span>
<span class="kn">import</span> <span class="n">matplotlib</span>
<span class="n">matplotlib</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="sh">'</span><span class="s">figure.figsize</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mf">8.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">)</span>
<span class="n">imp_coef</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">kind</span> <span class="o">=</span> <span class="sh">"</span><span class="s">barh</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">"</span><span class="s">Feature importance using Lasso Model</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/img/Node_Prediction/output_136_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">feature_selector</span> <span class="kn">import</span> <span class="n">FeatureSelector</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fs</span> <span class="o">=</span> <span class="nc">FeatureSelector</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">X</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fs</span><span class="p">.</span><span class="nf">identify_missing</span><span class="p">(</span><span class="n">missing_threshold</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">)</span>
<span class="n">fs</span><span class="p">.</span><span class="n">missing_stats</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0 features with greater than 0.60 missing values.
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fs</span><span class="p">.</span><span class="nf">identify_collinear</span><span class="p">(</span><span class="n">correlation_threshold</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0 features with a correlation magnitude greater than 0.50.
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Pass in the appropriate parameters
</span><span class="n">fs</span><span class="p">.</span><span class="nf">identify_zero_importance</span><span class="p">(</span><span class="n">task</span> <span class="o">=</span> <span class="sh">'</span><span class="s">classification</span><span class="sh">'</span><span class="p">,</span> 
                            <span class="n">eval_metric</span> <span class="o">=</span> <span class="sh">'</span><span class="s">auc</span><span class="sh">'</span><span class="p">,</span> 
                            <span class="n">n_iterations</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> 
                             <span class="n">early_stopping</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="c1"># list of zero importance features
</span><span class="n">zero_importance_features</span> <span class="o">=</span> <span class="n">fs</span><span class="p">.</span><span class="n">ops</span><span class="p">[</span><span class="sh">'</span><span class="s">zero_importance</span><span class="sh">'</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Training Gradient Boosting Model

Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[113]	valid_0's auc: 0.918258	valid_0's binary_logloss: 0.166625
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[136]	valid_0's auc: 0.920733	valid_0's binary_logloss: 0.16579
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[114]	valid_0's auc: 0.933337	valid_0's binary_logloss: 0.150962
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[87]	valid_0's auc: 0.92038	valid_0's binary_logloss: 0.168393
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[50]	valid_0's auc: 0.92073	valid_0's binary_logloss: 0.188329
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[105]	valid_0's auc: 0.913405	valid_0's binary_logloss: 0.169875
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[100]	valid_0's auc: 0.944989	valid_0's binary_logloss: 0.148649
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[62]	valid_0's auc: 0.903135	valid_0's binary_logloss: 0.207652
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[92]	valid_0's auc: 0.938784	valid_0's binary_logloss: 0.149928
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[115]	valid_0's auc: 0.910397	valid_0's binary_logloss: 0.191539

0 features with zero importance after one-hot encoding.
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># plot the feature importances
</span><span class="n">fs</span><span class="p">.</span><span class="nf">plot_feature_importances</span><span class="p">(</span><span class="n">threshold</span> <span class="o">=</span> <span class="mf">0.99</span><span class="p">,</span> <span class="n">plot_n</span> <span class="o">=</span> <span class="mi">12</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/img/Node_Prediction/output_142_0.png" alt="png" /></p>

<p><img src="/img/Node_Prediction/output_142_1.png" alt="png" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>5 features required for 0.99 of cumulative importance
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fs</span><span class="p">.</span><span class="nf">identify_low_importance</span><span class="p">(</span><span class="n">cumulative_importance</span> <span class="o">=</span> <span class="mf">0.99</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>4 features required for cumulative importance of 0.99 after one hot encoding.
1 features do not contribute to cumulative importance of 0.99.
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fs</span><span class="p">.</span><span class="nf">identify_single_unique</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0 features with a single unique value.
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fs</span><span class="p">.</span><span class="nf">plot_unique</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/img/Node_Prediction/output_145_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_removed</span> <span class="o">=</span> <span class="n">fs</span><span class="p">.</span><span class="nf">remove</span><span class="p">(</span><span class="n">methods</span> <span class="o">=</span> <span class="sh">'</span><span class="s">all</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>['missing', 'collinear', 'zero_importance', 'low_importance', 'single_unique'] methods have been run

Removed 1 features.
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_removed</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_removed_all</span> <span class="o">=</span> <span class="n">fs</span><span class="p">.</span><span class="nf">remove</span><span class="p">(</span><span class="n">methods</span> <span class="o">=</span> <span class="sh">'</span><span class="s">all</span><span class="sh">'</span><span class="p">,</span> <span class="n">keep_one_hot</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>['missing', 'collinear', 'zero_importance', 'low_importance', 'single_unique'] methods have been run

Removed 1 features including one-hot features.
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_removed_all</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fs</span><span class="p">.</span><span class="nf">identify_all</span><span class="p">(</span><span class="n">selection_params</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">missing_threshold</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.6</span><span class="p">,</span>    
                                    <span class="sh">'</span><span class="s">correlation_threshold</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.98</span><span class="p">,</span> 
                                    <span class="sh">'</span><span class="s">task</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">classification</span><span class="sh">'</span><span class="p">,</span>    
                                    <span class="sh">'</span><span class="s">eval_metric</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">auc</span><span class="sh">'</span><span class="p">,</span> 
                                    <span class="sh">'</span><span class="s">cumulative_importance</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.99</span><span class="p">})</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0 features with greater than 0.60 missing values.

0 features with a single unique value.

0 features with a correlation magnitude greater than 0.98.

Training Gradient Boosting Model

Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[99]	valid_0's auc: 0.910872	valid_0's binary_logloss: 0.186959
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[102]	valid_0's auc: 0.892063	valid_0's binary_logloss: 0.186904
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[74]	valid_0's auc: 0.921257	valid_0's binary_logloss: 0.187569
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[120]	valid_0's auc: 0.922538	valid_0's binary_logloss: 0.170568
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[79]	valid_0's auc: 0.923534	valid_0's binary_logloss: 0.163693
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[147]	valid_0's auc: 0.92	valid_0's binary_logloss: 0.17738
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[35]	valid_0's auc: 0.916405	valid_0's binary_logloss: 0.18372
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[136]	valid_0's auc: 0.910572	valid_0's binary_logloss: 0.190256
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[106]	valid_0's auc: 0.919383	valid_0's binary_logloss: 0.166765
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[107]	valid_0's auc: 0.914182	valid_0's binary_logloss: 0.175298

0 features with zero importance after one-hot encoding.

4 features required for cumulative importance of 0.99 after one hot encoding.
1 features do not contribute to cumulative importance of 0.99.

1 total features out of 5 identified for removal after one-hot encoding.
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">nodes_with_conflict</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">ddf</span><span class="p">[</span><span class="n">ddf</span><span class="p">[</span><span class="sh">'</span><span class="s">conflict</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">][</span><span class="sh">'</span><span class="s">IndividualId</span><span class="sh">'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">nodes_without_conflict</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">ddf</span><span class="p">[</span><span class="n">ddf</span><span class="p">[</span><span class="sh">'</span><span class="s">conflict</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">][</span><span class="sh">'</span><span class="s">IndividualId</span><span class="sh">'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">set</span><span class="p">(</span><span class="n">nodes_with_conflict</span><span class="p">)</span> <span class="o">==</span> <span class="nf">set</span><span class="p">(</span><span class="n">nodes_without_conflict</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>False
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">big_df_with_conflict</span> <span class="o">=</span> <span class="n">big_df</span><span class="p">[</span><span class="n">big_df</span><span class="p">[</span><span class="sh">'</span><span class="s">node</span><span class="sh">'</span><span class="p">].</span><span class="nf">isin</span><span class="p">(</span><span class="n">nodes_with_conflict</span><span class="p">)]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">big_df_without_conflict</span> <span class="o">=</span> <span class="n">big_df</span><span class="p">[</span><span class="n">big_df</span><span class="p">[</span><span class="sh">'</span><span class="s">node</span><span class="sh">'</span><span class="p">].</span><span class="nf">isin</span><span class="p">(</span><span class="n">nodes_without_conflict</span><span class="p">)]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">pandarallel</span> <span class="kn">import</span> <span class="n">pandarallel</span>
<span class="n">pandarallel</span><span class="p">.</span><span class="nf">initialize</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">inv</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">x</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">0</span>
    <span class="k">elif</span> <span class="n">x</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">1</span>
<span class="n">big_df</span><span class="p">[</span><span class="sh">'</span><span class="s">depart</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">big_df</span><span class="p">[</span><span class="sh">'</span><span class="s">depart</span><span class="sh">'</span><span class="p">].</span><span class="nf">parallel_apply</span><span class="p">(</span><span class="n">inv</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>New pandarallel memory created - Size: 2000 MB
Pandarallel will run on 8 workers
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X</span> <span class="o">=</span> <span class="n">big_df_with_conflict</span><span class="p">[[</span><span class="sh">'</span><span class="s">close</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">between</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">eigen</span><span class="sh">'</span><span class="p">]]</span>  <span class="c1">#independent columns
</span><span class="n">y</span> <span class="o">=</span> <span class="n">big_df_with_conflict</span><span class="p">[[</span><span class="sh">'</span><span class="s">depart</span><span class="sh">'</span><span class="p">]]</span>    <span class="c1">#target column i.e price range
</span><span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">ExtraTreesClassifier</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">model</span> <span class="o">=</span> <span class="nc">ExtraTreesClassifier</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">feature_importances_</span><span class="p">)</span> <span class="c1">#use inbuilt class feature_importances of tree based classifiers
#plot graph of feature importances for better visualization
</span><span class="n">feat_importances</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">Series</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">feature_importances_</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">X</span><span class="p">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">feat_importances</span><span class="p">.</span><span class="nf">nlargest</span><span class="p">(</span><span class="mi">5</span><span class="p">).</span><span class="nf">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="sh">'</span><span class="s">barh</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[0.59650393 0.09559814 0.30789793]
</code></pre></div></div>

<p><img src="/img/Node_Prediction/output_157_2.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X</span> <span class="o">=</span> <span class="n">big_df_without_conflict</span><span class="p">[[</span><span class="sh">'</span><span class="s">close</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">between</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">eigen</span><span class="sh">'</span><span class="p">]]</span>  <span class="c1">#independent columns
</span><span class="n">y</span> <span class="o">=</span> <span class="n">big_df_without_conflict</span><span class="p">[[</span><span class="sh">'</span><span class="s">depart</span><span class="sh">'</span><span class="p">]]</span>    <span class="c1">#target column i.e price range
</span><span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">ExtraTreesClassifier</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">model</span> <span class="o">=</span> <span class="nc">ExtraTreesClassifier</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">feature_importances_</span><span class="p">)</span> <span class="c1">#use inbuilt class feature_importances of tree based classifiers
#plot graph of feature importances for better visualization
</span><span class="n">feat_importances</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">Series</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">feature_importances_</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">X</span><span class="p">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">feat_importances</span><span class="p">.</span><span class="nf">nlargest</span><span class="p">(</span><span class="mi">5</span><span class="p">).</span><span class="nf">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="sh">'</span><span class="s">barh</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[0.59563847 0.07901322 0.32534832]
</code></pre></div></div>

<p><img src="/img/Node_Prediction/output_158_2.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">len</span><span class="p">(</span><span class="n">big_df_with_conflict</span><span class="p">),</span> <span class="nf">len</span><span class="p">(</span><span class="n">big_df_without_conflict</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(5915, 780)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fs</span> <span class="o">=</span> <span class="nc">FeatureSelector</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">X</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fs</span><span class="p">.</span><span class="nf">identify_collinear</span><span class="p">(</span><span class="n">correlation_threshold</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2 features with a correlation magnitude greater than 0.50.
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Pass in the appropriate parameters
</span><span class="n">fs</span><span class="p">.</span><span class="nf">identify_zero_importance</span><span class="p">(</span><span class="n">task</span> <span class="o">=</span> <span class="sh">'</span><span class="s">classification</span><span class="sh">'</span><span class="p">,</span> 
                            <span class="n">eval_metric</span> <span class="o">=</span> <span class="sh">'</span><span class="s">auc</span><span class="sh">'</span><span class="p">,</span> 
                            <span class="n">n_iterations</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> 
                             <span class="n">early_stopping</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="c1"># list of zero importance features
</span><span class="n">zero_importance_features</span> <span class="o">=</span> <span class="n">fs</span><span class="p">.</span><span class="n">ops</span><span class="p">[</span><span class="sh">'</span><span class="s">zero_importance</span><span class="sh">'</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Training Gradient Boosting Model

Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[91]	valid_0's auc: 0.990654	valid_0's binary_logloss: 0.106263
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[164]	valid_0's auc: 0.973625	valid_0's binary_logloss: 0.149786
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[103]	valid_0's auc: 0.939869	valid_0's binary_logloss: 0.197257
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[3]	valid_0's auc: 0.972772	valid_0's binary_logloss: 0.339178
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[27]	valid_0's auc: 0.974852	valid_0's binary_logloss: 0.173048
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[126]	valid_0's auc: 0.942535	valid_0's binary_logloss: 0.217243
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[19]	valid_0's auc: 0.886644	valid_0's binary_logloss: 0.292342
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[85]	valid_0's auc: 0.924411	valid_0's binary_logloss: 0.209373
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[113]	valid_0's auc: 0.956186	valid_0's binary_logloss: 0.202166
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[55]	valid_0's auc: 0.94248	valid_0's binary_logloss: 0.230042

0 features with zero importance after one-hot encoding.
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fs</span><span class="p">.</span><span class="nf">identify_low_importance</span><span class="p">(</span><span class="n">cumulative_importance</span> <span class="o">=</span> <span class="mf">0.99</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>4 features required for cumulative importance of 0.99 after one hot encoding.
1 features do not contribute to cumulative importance of 0.99.
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#train_removed_all = fs.remove(methods = 'all', keep_one_hot=False)
</span><span class="n">train_removed_all</span> <span class="o">=</span> <span class="n">fs</span><span class="p">.</span><span class="nf">remove</span><span class="p">(</span><span class="n">methods</span> <span class="o">=</span> <span class="sh">'</span><span class="s">all</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>['collinear', 'zero_importance', 'low_importance'] methods have been run

Removed 3 features.
</code></pre></div></div>


            </div>
          </article>

          <style>
          .card {
            border: none;
            box-shadow: 0 5px 15px rgba(0,0,0,0.08);
            transition: transform 0.3s ease;
          }

          .card:hover {
            transform: translateY(-5px);
          }

          .card-header {
            background: none;
            border: none;
            padding: 2rem 1.5rem;
          }

          .card-meta {
            color: #666;
            font-size: 0.9rem;
            margin-bottom: 1rem;
          }

          .card-meta a {
            color: #EA950B;
            margin: 0 0.5rem;
            transition: color 0.3s ease;
          }

          .card-title {
            color: #333;
            font-size: 2rem;
            font-weight: 700;
          }

          .card-img-wrapper {
            overflow: hidden;
          }

          .card-img {
            transition: transform 0.5s ease;
          }

          .card-img:hover {
            transform: scale(1.05);
          }

          .card-body {
            padding: 2rem;
            font-size: 1.1rem;
            line-height: 1.8;
          }
          </style>
        </div>
		<style>
  /* Styles gnraux */
  h4.card-title {
    font-family: 'Roboto', sans-serif;
    color: #EA950B;
    padding-bottom: 10px;
  }

  .card {
    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
    transition: all 0.3s;
  }

  .card:hover {
    transform: translateY(-5px);
  }

  .btn-link {
    color: #007bff;
    transition: color 0.3s;
  }

  .btn-link:hover {
    color: #0056b3;
    text-decoration: underline;
  }

  .card-img {
    width: 100%;
    height: auto;
    border-radius: 5px;
    margin-top: 10px;
  }

  time {
    color: #888;
    font-size: 14px;
  }
</style>

<div class="col-md-3 ml-auto">
  <aside class="sidebar sidebar-sticky">
    <!-- Card for Categories -->
    <div class="card mb-4">
      <div class="card-body">
        <h4 class="card-title">Categories</h4>
        <ul class="list-unstyled">
          
          
          <li>
            <a class="btn btn-link btn-sm" href="/categories/#Computer Science">
              Computer Science
            </a>
          </li>
          
          
          <li>
            <a class="btn btn-link btn-sm" href="/categories/#Data Engineering">
              Data Engineering
            </a>
          </li>
          
          
          <li>
            <a class="btn btn-link btn-sm" href="/categories/#Mathematics">
              Mathematics
            </a>
          </li>
          
          
          <li>
            <a class="btn btn-link btn-sm" href="/categories/#Graph Theory">
              Graph Theory
            </a>
          </li>
          
          
          <li>
            <a class="btn btn-link btn-sm" href="/categories/#Machine Learning">
              Machine Learning
            </a>
          </li>
          
          
          <li>
            <a class="btn btn-link btn-sm" href="/categories/#Graph Learning">
              Graph Learning
            </a>
          </li>
          
          
          <li>
            <a class="btn btn-link btn-sm" href="/categories/#Data Science">
              Data Science
            </a>
          </li>
          
          
          <li>
            <a class="btn btn-link btn-sm" href="/categories/#Cloud Computing">
              Cloud Computing
            </a>
          </li>
          
          
          <li>
            <a class="btn btn-link btn-sm" href="/categories/#Analytics Engineering">
              Analytics Engineering
            </a>
          </li>
          
          
          <li>
            <a class="btn btn-link btn-sm" href="/categories/#DevOps">
              DevOps
            </a>
          </li>
          
          
          <li>
            <a class="btn btn-link btn-sm" href="/categories/#Artificial Intelligence">
              Artificial Intelligence
            </a>
          </li>
          
          
          <li>
            <a class="btn btn-link btn-sm" href="/categories/#Technology">
              Technology
            </a>
          </li>
          
          
          <li>
            <a class="btn btn-link btn-sm" href="/categories/#Innovation">
              Innovation
            </a>
          </li>
          
          
          <li>
            <a class="btn btn-link btn-sm" href="/categories/#Data Architecture">
              Data Architecture
            </a>
          </li>
          
          
          <li>
            <a class="btn btn-link btn-sm" href="/categories/#Decentralization">
              Decentralization
            </a>
          </li>
          
          
          <li>
            <a class="btn btn-link btn-sm" href="/categories/#Database Technology">
              Database Technology
            </a>
          </li>
          
          
          <li>
            <a class="btn btn-link btn-sm" href="/categories/#Graph Databases">
              Graph Databases
            </a>
          </li>
          
          
          <li>
            <a class="btn btn-link btn-sm" href="/categories/#Neo4j">
              Neo4j
            </a>
          </li>
          
        </ul>
      </div>
    </div>

    <!-- Card for Latest Posts -->
    <div class="card mb-4">
      <div class="card-body">
        <h4 class="card-title">Latest posts</h4>
        
        <div class="post-item">
          <a href="/database%20technology/graph%20databases/neo4j/2023/11/21/neo4j/">
            <h4 class="h6">Exploring Neo4j in 2023: The Evolution of Graph Databases</h4>
            
            <img class="card-img" src="/img/neo4j.png" alt="Exploring Neo4j in 2023: The Evolution of Graph Databases" />
            
          </a>
          <time>On 21 Nov 2023</time> in Database Technology
          <hr />
        </div>
        
        <div class="post-item">
          <a href="/data%20architecture/data%20engineering/decentralization/2023/10/28/datamesh/">
            <h4 class="h6">Unveiling Data Mesh: Decentralizing Data at Scale</h4>
            
            <img class="card-img" src="/img/datamesh.png" alt="Unveiling Data Mesh: Decentralizing Data at Scale" />
            
          </a>
          <time>On 28 Oct 2023</time> in Data Architecture
          <hr />
        </div>
        
      </div>
    </div>
  </aside>
</div>	
      </div>
    </div>
  </main>
<footer class="site-footer">
  <div class="container">
    <div class="row">
      <div class="col-md-4">
        <h3>About</h3>
        <p>Modern cloud, data, and AI architecture</p>
        <div class="social-links">
          <a href="https://github.com/" target="_blank"><i class="fab fa-github"></i></a>
          <a href="https://twitter.com/" target="_blank"><i class="fab fa-twitter"></i></a>
          <a href="https://linkedin.com/in/" target="_blank"><i class="fab fa-linkedin"></i></a>
        </div>
      </div>
      <div class="col-md-4">
        <h3>Recent Posts</h3>
        <ul class="recent-posts">
          
          <li><a href="/database%20technology/graph%20databases/neo4j/2023/11/21/neo4j/">Exploring Neo4j in 2023: The Evolution of Graph Databases</a></li>
          
          <li><a href="/data%20architecture/data%20engineering/decentralization/2023/10/28/datamesh/">Unveiling Data Mesh: Decentralizing Data at Scale</a></li>
          
          <li><a href="/devops/data%20engineering/cloud%20computing/2023/10/27/azuredevops/">Navigating Continuous Data Pipelines: An Extensive Look into CI/CD with Azure DevOps, dbt, Airflow, GCS, and BigQuery</a></li>
          
        </ul>
      </div>
      <div class="col-md-4">
        <h3>Newsletter</h3>
        <form class="newsletter-form">
          <input type="email" placeholder="Your email" required>
          <button type="submit">Subscribe</button>
        </form>
      </div>
    </div>
  </div>
  <div class="footer-bottom">
    <p>&copy; 2025 The Architect. All rights reserved.</p>
  </div>
</footer>

<style>
.site-footer {
  background: linear-gradient(135deg, #1a1a1a, #2d2d2d);
  color: #fff;
  padding: 4rem 0 0;
  margin-top: 4rem;
}

.site-footer h3 {
  color: #EA950B;
  font-size: 1.5rem;
  margin-bottom: 1.5rem;
  position: relative;
}

.site-footer h3::after {
  content: '';
  position: absolute;
  left: 0;
  bottom: -10px;
  width: 50px;
  height: 2px;
  background: #EA950B;
}

.social-links a {
  color: #fff;
  font-size: 1.5rem;
  margin-right: 1rem;
  transition: color 0.3s ease;
}

.social-links a:hover {
  color: #EA950B;
}

.recent-posts {
  list-style: none;
  padding: 0;
}

.recent-posts li {
  margin-bottom: 1rem;
}

.recent-posts a {
  color: #fff;
  text-decoration: none;
  transition: color 0.3s ease;
}

.recent-posts a:hover {
  color: #EA950B;
}

.newsletter-form {
  display: flex;
  gap: 0.5rem;
}

.newsletter-form input {
  flex: 1;
  padding: 0.75rem;
  border: none;
  border-radius: 4px;
  background: rgba(255,255,255,0.1);
  color: #fff;
}

.newsletter-form button {
  padding: 0.75rem 1.5rem;
  border: none;
  border-radius: 4px;
  background: #EA950B;
  color: #fff;
  cursor: pointer;
  transition: background 0.3s ease;
}

.newsletter-form button:hover {
  background: #ff8c00;
}

.footer-bottom {
  text-align: center;
  padding: 1.5rem 0;
  margin-top: 3rem;
  border-top: 1px solid rgba(255,255,255,0.1);
}
</style>

<script src="/js/bundle.js"></script>
</body>
</html>
