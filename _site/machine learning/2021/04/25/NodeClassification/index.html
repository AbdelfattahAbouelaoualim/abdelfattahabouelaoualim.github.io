<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="">
  <meta name="author" content="">
  <title> | How to do node classification and choose important features</title>

  <link href="/css/milo.css" rel="stylesheet">
  <link href="/fontawesome-free-5.12.1-web/css/all.css" rel="stylesheet"> <!--load all styles -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css" integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous">
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js" integrity="sha384-9Nhn55MVVN0/4OFx7EE5kpFBPsEMZxKTCnA+4fqDmg12eCTqGi6+BB2LjY8brQxJ" crossorigin="anonymous"></script>
 <script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>
</head>

<body>
<!-- Navigation -->

<nav class="navbar navbar-expand-lg navbar-light fixed-top" id="mainNav">
  <div class="container">
    <a class="navbar-brand" href="/">
    <img class="logo" src="/img/logo.png" alt="" style="object-fit:contain;
            width:120px;
            height:120px;"> 
    </a>
    <button class="navbar-toggler navbar-toggler-left" type="button" style="color:#FFFFFF" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
      Menu
      <i class="fa fa-bars"></i>
    </button>
    <div class="collapse navbar-collapse" id="navbarResponsive" >
      <ul class="navbar-nav ml-auto" id="main_nav">

        <li class="nav-item">
          <a style="color:#FFFFFF" class="nav-link" href="/">Home</a>
        </li>
        <li class="nav-item">
          <a style="color:#FFFFFF" class="nav-link" href="/about">About</a>
        </li>
        <li class="nav-item">
          <a style="color:#FFFFFF" class="nav-link" href="/author">Author</a>
        </li>

        <!--<li class="nav-item">
           <a style="color:#FFFFFF" class="nav-link" href="/contact">Contact</a> 
           
        </li>-->
      </ul>
    </div>
  </div>
</nav>


  <main class="main pt-4" role="main">

    <div class="container">

      <div class="row">
        <div class="col-md-9">

          <article class="card mb-4">
		  
            <header class="card-header text-center">
			
              <div class="card-meta">
                <span>Published on 25 Apr 2021</time></span> in
                  
                  
                  <a href="/categories/#Machine Learning">Machine Learning</a>
                  
                  
              <div>
			
                <h1 class="card-title">How to do node classification and choose important features</h1>

            </header>
			
			
            <a style="cursor:pointer;">
              <img class="card-img" src="/img/NodeClassification.jpg" alt="" />
            </a>
            
            
            <div class="card-body">
			<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="n">nx</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="kn">import</span> <span class="nn">stellargraph</span> <span class="k">as</span> <span class="n">sg</span>
<span class="kn">from</span> <span class="nn">stellargraph.mapper</span> <span class="kn">import</span> <span class="n">GraphSAGENodeGenerator</span>
<span class="kn">from</span> <span class="nn">stellargraph.layer</span> <span class="kn">import</span> <span class="n">GraphSAGE</span>

<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">layers</span><span class="p">,</span> <span class="n">optimizers</span><span class="p">,</span> <span class="n">losses</span><span class="p">,</span> <span class="n">metrics</span><span class="p">,</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">model_selection</span>
<span class="kn">from</span> <span class="nn">sklearn.utils</span> <span class="kn">import</span> <span class="n">class_weight</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">big_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"/data/big_df_2.csv"</span><span class="p">)</span>
<span class="n">big_df</span><span class="p">.</span><span class="n">drop</span><span class="p">([</span><span class="s">'Unnamed: 0'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">big_df</span><span class="p">[</span><span class="s">'Count'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">big_df</span><span class="p">[</span><span class="s">'count'</span><span class="p">]</span><span class="o">-</span><span class="n">big_df</span><span class="p">[</span><span class="s">'count'</span><span class="p">].</span><span class="n">mean</span><span class="p">())</span><span class="o">/</span><span class="n">big_df</span><span class="p">[</span><span class="s">'count'</span><span class="p">].</span><span class="n">std</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">big_df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">big_df_</span> <span class="o">=</span> <span class="n">big_df</span><span class="p">[</span><span class="n">big_df</span><span class="p">[</span><span class="s">'depart'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ddf</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"data/ddf_2.csv"</span><span class="p">)</span>
<span class="n">ddf</span><span class="p">.</span><span class="n">drop</span><span class="p">([</span><span class="s">'Unnamed: 0'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">ddf</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">big_G</span> <span class="o">=</span> <span class="n">nx</span><span class="p">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ddf</span><span class="p">.</span><span class="n">index</span><span class="p">:</span>
    <span class="n">big_G</span><span class="p">.</span><span class="n">add_edge</span><span class="p">(</span><span class="n">ddf</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s">'IndividualId'</span><span class="p">],</span> <span class="n">ddf</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s">'FatherIndividualId'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">list_nodes</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">big_df</span><span class="p">[</span><span class="s">'node'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">big_G</span> <span class="o">=</span> <span class="n">big_G</span><span class="p">.</span><span class="n">subgraph</span><span class="p">(</span><span class="n">list_nodes</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">list_nodes</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">big_G</span><span class="p">.</span><span class="n">nodes</span><span class="p">())</span>
<span class="n">big_df</span> <span class="o">=</span> <span class="n">big_df</span><span class="p">[</span><span class="n">big_df</span><span class="p">[</span><span class="s">'node'</span><span class="p">].</span><span class="n">isin</span><span class="p">(</span><span class="n">list_nodes</span><span class="p">)]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">big_df</span> <span class="o">=</span> <span class="n">big_df</span><span class="p">.</span><span class="n">set_index</span><span class="p">(</span><span class="s">'node'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_data</span><span class="p">,</span> <span class="n">test_data</span> <span class="o">=</span> <span class="n">model_selection</span><span class="p">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">big_df</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">big_df</span><span class="p">[</span><span class="s">'conflict'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_data</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">feature_names</span> <span class="o">=</span> <span class="p">[</span><span class="s">'eigen'</span><span class="p">,</span> <span class="s">'Count'</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">node_features</span> <span class="o">=</span> <span class="n">big_df</span><span class="p">[</span><span class="n">feature_names</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">node_features</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">node_features</span><span class="p">.</span><span class="n">describe</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">node_features</span><span class="p">.</span><span class="n">info</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
Int64Index: 6780 entries, 10004 to 9972
Data columns (total 2 columns):
eigen    6780 non-null float64
Count    6780 non-null float64
dtypes: float64(2)
memory usage: 158.9 KB
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">G</span> <span class="o">=</span> <span class="n">sg</span><span class="p">.</span><span class="n">StellarGraph</span><span class="p">(</span><span class="n">big_G</span><span class="p">,</span> <span class="n">node_features</span><span class="o">=</span><span class="n">node_features</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">G</span><span class="p">.</span><span class="n">info</span><span class="p">())</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>StellarGraph: Undirected multigraph
 Nodes: 6780, Edges: 7623

 Node types:
  default: [6780]
    Edge types: default-default-&gt;default

 Edge types:
    default-default-&gt;default: [7623]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">options</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'node_color'</span><span class="p">:</span> <span class="s">'blue'</span><span class="p">,</span>
    <span class="s">'node_size'</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
    <span class="s">'width'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    
<span class="p">}</span>
<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">18</span><span class="p">,</span><span class="mi">18</span><span class="p">))</span>
<span class="n">nx</span><span class="p">.</span><span class="n">draw</span><span class="p">(</span><span class="n">big_G</span><span class="p">,</span> <span class="n">with_labels</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span> <span class="o">**</span><span class="n">options</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/img/Node_Prediction/output_28_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="n">Counter</span><span class="p">(</span><span class="n">train_data</span><span class="p">[</span><span class="s">'conflict'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Counter({0.0: 3250, 1.0: 2174})
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">missingno</span> <span class="k">as</span> <span class="n">msno</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">msno</span><span class="p">.</span><span class="n">bar</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/img/Node_Prediction/output_31_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">nx</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="n">big_G</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Name: 
Type: Graph
Number of nodes: 741
Number of edges: 164
Average degree:   0.4426
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">80</span><span class="p">;</span> <span class="n">num_samples</span> <span class="o">=</span> <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">15</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">generator</span> <span class="o">=</span> <span class="n">GraphSAGENodeGenerator</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_gen</span> <span class="o">=</span> <span class="n">generator</span><span class="p">.</span><span class="n">flow</span><span class="p">(</span><span class="n">train_data</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">train_data</span><span class="p">[[</span><span class="s">"conflict"</span><span class="p">]]))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">graphsage_model</span> <span class="o">=</span> <span class="n">GraphSAGE</span><span class="p">(</span>
    <span class="n">layer_sizes</span><span class="o">=</span><span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">],</span>
    <span class="n">generator</span><span class="o">=</span><span class="n">train_gen</span><span class="p">,</span>
    <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="c1">#aggregator=sg.layer.graphsage.MeanAggregator
</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#from keras import layers, optimizers, losses, metrics, Model
</span></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x_inp</span><span class="p">,</span> <span class="n">x_out</span> <span class="o">=</span> <span class="n">graphsage_model</span><span class="p">.</span><span class="n">build</span><span class="p">()</span>

<span class="n">prediction</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">train_data</span><span class="p">[[</span><span class="s">"conflict"</span><span class="p">]]).</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">activation</span><span class="o">=</span><span class="s">"sigmoid"</span><span class="p">)(</span><span class="n">x_out</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">keras</span><span class="p">.</span><span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">x_inp</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">prediction</span><span class="p">)</span>

<span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span>
    <span class="n">optimizer</span><span class="o">=</span><span class="n">keras</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.1</span><span class="p">),</span>
    <span class="n">loss</span><span class="o">=</span><span class="n">keras</span><span class="p">.</span><span class="n">losses</span><span class="p">.</span><span class="n">binary_crossentropy</span><span class="p">,</span>
    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">"acc"</span><span class="p">]</span>
<span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test_gen</span> <span class="o">=</span> <span class="n">generator</span><span class="p">.</span><span class="n">flow</span><span class="p">(</span><span class="n">test_data</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">test_data</span><span class="p">[[</span><span class="s">"conflict"</span><span class="p">]]))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">fit_generator</span><span class="p">(</span>
    <span class="n">train_gen</span><span class="p">,</span>
    <span class="n">steps_per_epoch</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">big_df</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="n">test_gen</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span>
<span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Epoch 1/25
84/84 - 5s - loss: 0.6341 - acc: 0.6411 - val_loss: 0.5891 - val_acc: 0.7139
Epoch 2/25
84/84 - 4s - loss: 0.5809 - acc: 0.7139 - val_loss: 0.6199 - val_acc: 0.6822
Epoch 3/25
84/84 - 4s - loss: 0.5795 - acc: 0.7123 - val_loss: 0.5800 - val_acc: 0.7205
Epoch 4/25
84/84 - 4s - loss: 0.5816 - acc: 0.7096 - val_loss: 0.5739 - val_acc: 0.7227
Epoch 5/25
84/84 - 4s - loss: 0.5811 - acc: 0.7114 - val_loss: 0.6003 - val_acc: 0.7198
Epoch 6/25
84/84 - 4s - loss: 0.5774 - acc: 0.7143 - val_loss: 0.5906 - val_acc: 0.7153
Epoch 7/25
84/84 - 4s - loss: 0.5764 - acc: 0.7176 - val_loss: 0.6150 - val_acc: 0.6807
Epoch 8/25
84/84 - 4s - loss: 0.5806 - acc: 0.7088 - val_loss: 0.5750 - val_acc: 0.7308
Epoch 9/25
84/84 - 4s - loss: 0.5741 - acc: 0.7146 - val_loss: 0.5868 - val_acc: 0.7227
Epoch 10/25
84/84 - 4s - loss: 0.5766 - acc: 0.7145 - val_loss: 0.5747 - val_acc: 0.7301
Epoch 11/25
84/84 - 4s - loss: 0.5767 - acc: 0.7117 - val_loss: 0.6028 - val_acc: 0.7050
Epoch 12/25
84/84 - 4s - loss: 0.5804 - acc: 0.7103 - val_loss: 0.5772 - val_acc: 0.7235
Epoch 13/25
84/84 - 5s - loss: 0.5744 - acc: 0.7158 - val_loss: 0.5764 - val_acc: 0.7301
Epoch 14/25
84/84 - 4s - loss: 0.5754 - acc: 0.7179 - val_loss: 0.5916 - val_acc: 0.7102
Epoch 15/25
84/84 - 4s - loss: 0.5752 - acc: 0.7155 - val_loss: 0.5748 - val_acc: 0.7271
Epoch 16/25
84/84 - 4s - loss: 0.5754 - acc: 0.7120 - val_loss: 0.5840 - val_acc: 0.7035
Epoch 17/25
84/84 - 4s - loss: 0.5795 - acc: 0.7099 - val_loss: 0.5743 - val_acc: 0.7316
Epoch 18/25
84/84 - 5s - loss: 0.5737 - acc: 0.7157 - val_loss: 0.5774 - val_acc: 0.7308
Epoch 19/25
84/84 - 5s - loss: 0.5737 - acc: 0.7158 - val_loss: 0.5821 - val_acc: 0.7257
Epoch 20/25
84/84 - 5s - loss: 0.5713 - acc: 0.7160 - val_loss: 0.5878 - val_acc: 0.7183
Epoch 21/25
84/84 - 4s - loss: 0.5744 - acc: 0.7136 - val_loss: 0.5817 - val_acc: 0.7249
Epoch 22/25
84/84 - 4s - loss: 0.5673 - acc: 0.7176 - val_loss: 0.6048 - val_acc: 0.7183
Epoch 23/25
84/84 - 4s - loss: 0.5735 - acc: 0.7187 - val_loss: 0.5852 - val_acc: 0.7286
Epoch 24/25
84/84 - 5s - loss: 0.5713 - acc: 0.7182 - val_loss: 0.6155 - val_acc: 0.6822
Epoch 25/25
84/84 - 5s - loss: 0.5758 - acc: 0.7094 - val_loss: 0.5701 - val_acc: 0.7345
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>

<span class="k">def</span> <span class="nf">plot_history</span><span class="p">(</span><span class="n">history</span><span class="p">):</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">.</span><span class="n">keys</span><span class="p">())</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="n">metrics</span><span class="p">[:</span><span class="nb">len</span><span class="p">(</span><span class="n">metrics</span><span class="p">)</span><span class="o">//</span><span class="mi">2</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">metrics</span><span class="p">:</span>
        <span class="c1"># summarize history for metric m
</span>        <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="n">m</span><span class="p">])</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">.</span><span class="n">history</span><span class="p">[</span><span class="s">'val_'</span> <span class="o">+</span> <span class="n">m</span><span class="p">])</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'epoch'</span><span class="p">)</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">([</span><span class="s">'train'</span><span class="p">,</span> <span class="s">'test'</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s">'best'</span><span class="p">)</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plot_history</span><span class="p">(</span><span class="n">history</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/img/Node_Prediction/output_44_0.png" alt="png" /></p>

<p><img src="/img/Node_Prediction/output_44_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">multiprocessing</span>
<span class="n">num_workers</span> <span class="o">=</span> <span class="n">multiprocessing</span><span class="p">.</span><span class="n">cpu_count</span><span class="p">()</span><span class="o">//</span><span class="mi">2</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_metrics</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">evaluate_generator</span><span class="p">(</span><span class="n">train_gen</span><span class="p">,</span> <span class="n">use_multiprocessing</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">test_metrics</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">evaluate_generator</span><span class="p">(</span><span class="n">test_gen</span><span class="p">,</span> <span class="n">use_multiprocessing</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">Train Set Metrics of the trained model:"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">metrics_names</span><span class="p">,</span> <span class="n">train_metrics</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\t</span><span class="s">{}: {:0.4f}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">val</span><span class="p">))</span>

<span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">Test Set Metrics of the trained model:"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">metrics_names</span><span class="p">,</span> <span class="n">test_metrics</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\t</span><span class="s">{}: {:0.4f}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">val</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>68/68 [==============================] - 1s 17ms/step - loss: 0.5598 - acc: 0.7303
17/17 [==============================] - 0s 22ms/step - loss: 0.5717 - acc: 0.7308

Train Set Metrics of the trained model:
	loss: 0.5598
	acc: 0.7303

Test Set Metrics of the trained model:
	loss: 0.5717
	acc: 0.7308
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">test_data</span><span class="p">[[</span><span class="s">"conflict"</span><span class="p">]])</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict_generator</span><span class="p">(</span><span class="n">test_gen</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">around</span><span class="p">(</span><span class="n">y_pred</span><span class="p">),</span> <span class="n">y_true</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>              precision    recall  f1-score   support

         0.0       0.84      0.74      0.79       920
         1.0       0.57      0.71      0.63       436

    accuracy                           0.73      1356
   macro avg       0.70      0.73      0.71      1356
weighted avg       0.75      0.73      0.74      1356
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">test_metrics</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">evaluate_generator</span><span class="p">(</span><span class="n">test_gen</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">Test Set Metrics:"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">metrics_names</span><span class="p">,</span> <span class="n">test_metrics</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\t</span><span class="s">{}: {:0.4f}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">val</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Test Set Metrics:
	loss: 0.6371
	acc: 0.5906
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">precision_recall_fscore_support</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">precision_recall_fscore_support</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">test_data</span><span class="p">[</span><span class="s">'depart'</span><span class="p">]),</span> <span class="n">np</span><span class="p">.</span><span class="n">around</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">predict_generator</span><span class="p">(</span><span class="n">generator</span><span class="p">.</span><span class="n">flow</span><span class="p">(</span><span class="n">test_data</span><span class="p">[</span><span class="n">feature_names</span><span class="p">].</span><span class="n">index</span><span class="p">))),</span> <span class="n">average</span><span class="o">=</span><span class="s">'macro'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(0.8549472020841564, 0.6859450510112762, 0.7364412336901534, None)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">precision_recall_fscore_support</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">test_data</span><span class="p">[</span><span class="s">'depart'</span><span class="p">]),</span> <span class="n">np</span><span class="p">.</span><span class="n">around</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">predict_generator</span><span class="p">(</span><span class="n">generator</span><span class="p">.</span><span class="n">flow</span><span class="p">(</span><span class="n">test_data</span><span class="p">[</span><span class="n">feature_names</span><span class="p">].</span><span class="n">index</span><span class="p">))),</span> <span class="n">average</span><span class="o">=</span><span class="s">'micro'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(0.9210914454277286, 0.9210914454277286, 0.9210914454277286, None)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">precision_recall_fscore_support</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">test_data</span><span class="p">[</span><span class="s">'depart'</span><span class="p">]),</span> <span class="n">np</span><span class="p">.</span><span class="n">around</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">predict_generator</span><span class="p">(</span><span class="n">generator</span><span class="p">.</span><span class="n">flow</span><span class="p">(</span><span class="n">test_data</span><span class="p">[</span><span class="n">feature_names</span><span class="p">].</span><span class="n">index</span><span class="p">))),</span> <span class="n">average</span><span class="o">=</span><span class="s">'weighted'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(0.9126711939188366, 0.9210914454277286, 0.909333076064201, None)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">num_tests</span> <span class="o">=</span> <span class="mi">1</span> <span class="c1"># the number of times to generate predictions
</span><span class="n">all_test_predictions</span> <span class="o">=</span> <span class="p">[</span><span class="n">model</span><span class="p">.</span><span class="n">predict_generator</span><span class="p">(</span><span class="n">test_gen</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">num_tests</span><span class="p">)]</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>17/17 [==============================] - 1s 51ms/step
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.calibration</span> <span class="kn">import</span> <span class="n">calibration_curve</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">calibration_data</span> <span class="o">=</span> <span class="p">[</span><span class="n">calibration_curve</span><span class="p">(</span><span class="n">y_prob</span><span class="o">=</span><span class="n">test_predictions</span><span class="p">,</span> 
                                      <span class="n">y_true</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">test_data</span><span class="p">[</span><span class="s">'depart'</span><span class="p">]),</span> 
                                      <span class="n">n_bins</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> 
                                      <span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">test_predictions</span> <span class="ow">in</span> <span class="n">all_test_predictions</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">stellargraph</span> <span class="kn">import</span> <span class="n">expected_calibration_error</span><span class="p">,</span> <span class="n">plot_reliability_diagram</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">fraction_of_positives</span><span class="p">,</span> <span class="n">mean_predicted_value</span> <span class="ow">in</span> <span class="n">calibration_data</span><span class="p">:</span>
    <span class="n">ece_pre_calibration</span> <span class="o">=</span> <span class="n">expected_calibration_error</span><span class="p">(</span><span class="n">prediction_probabilities</span><span class="o">=</span><span class="n">all_test_predictions</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> 
                                                     <span class="n">accuracy</span><span class="o">=</span><span class="n">fraction_of_positives</span><span class="p">,</span> 
                                                     <span class="n">confidence</span><span class="o">=</span><span class="n">mean_predicted_value</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'ECE: (before calibration) {:.4f}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">ece_pre_calibration</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ECE: (before calibration) 0.0211
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plot_reliability_diagram</span><span class="p">(</span><span class="n">calibration_data</span><span class="p">,</span> 
                         <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">all_test_predictions</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> 
                         <span class="n">ece</span><span class="o">=</span><span class="p">[</span><span class="n">ece_pre_calibration</span><span class="p">])</span>
</code></pre></div></div>

<p><img src="/img/Node_Prediction/output_61_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">use_platt</span> <span class="o">=</span> <span class="bp">False</span>  <span class="c1"># True for Platt scaling or False for Isotonic Regression
</span><span class="n">num_tests</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">score_model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">x_inp</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">prediction</span><span class="p">)</span>
<span class="k">if</span> <span class="n">use_platt</span><span class="p">:</span>
    <span class="n">all_test_score_predictions</span> <span class="o">=</span> <span class="p">[</span><span class="n">score_model</span><span class="p">.</span><span class="n">predict_generator</span><span class="p">(</span><span class="n">test_gen</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">num_tests</span><span class="p">)]</span>
    <span class="n">all_test_probabilistic_predictions</span> <span class="o">=</span> <span class="p">[</span><span class="n">model</span><span class="p">.</span><span class="n">predict_generator</span><span class="p">(</span><span class="n">test_gen</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">num_tests</span><span class="p">)]</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">all_test_probabilistic_predictions</span> <span class="o">=</span> <span class="p">[</span><span class="n">model</span><span class="p">.</span><span class="n">predict_generator</span><span class="p">(</span><span class="n">test_gen</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">num_tests</span><span class="p">)]</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>17/17 [==============================] - 1s 57ms/step
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># These are the uncalibrated prediction probabilities. 
</span><span class="k">if</span> <span class="n">use_platt</span><span class="p">:</span>
    <span class="n">test_predictions</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">all_test_score_predictions</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">test_predictions</span><span class="p">.</span><span class="n">shape</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">test_predictions</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">all_test_probabilistic_predictions</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">test_predictions</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">stellargraph</span> <span class="kn">import</span> <span class="n">IsotonicCalibration</span><span class="p">,</span> <span class="n">TemperatureCalibration</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">if</span> <span class="n">use_platt</span><span class="p">:</span>
    <span class="c1"># for binary classification this class performs Platt Scaling
</span>    <span class="n">lr</span> <span class="o">=</span> <span class="n">TemperatureCalibration</span><span class="p">()</span>  
<span class="k">else</span><span class="p">:</span>
    <span class="n">lr</span> <span class="o">=</span> <span class="n">IsotonicCalibration</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lr</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">test_predictions</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">test_data</span><span class="p">[</span><span class="s">'depart'</span><span class="p">]))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lr_test_predictions</span> <span class="o">=</span> <span class="n">lr</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_predictions</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">calibration_data</span> <span class="o">=</span> <span class="p">[</span><span class="n">calibration_curve</span><span class="p">(</span><span class="n">y_prob</span><span class="o">=</span><span class="n">lr_test_predictions</span><span class="p">,</span> 
                                      <span class="n">y_true</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">test_data</span><span class="p">[</span><span class="s">'depart'</span><span class="p">]),</span> 
                                      <span class="n">n_bins</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> 
                                      <span class="n">normalize</span><span class="o">=</span><span class="bp">True</span><span class="p">)]</span> 
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">fraction_of_positives</span><span class="p">,</span> <span class="n">mean_predicted_value</span> <span class="ow">in</span> <span class="n">calibration_data</span><span class="p">:</span>
    <span class="n">ece_post_calibration</span> <span class="o">=</span> <span class="n">expected_calibration_error</span><span class="p">(</span><span class="n">prediction_probabilities</span><span class="o">=</span><span class="n">lr_test_predictions</span><span class="p">,</span> 
                                                      <span class="n">accuracy</span><span class="o">=</span><span class="n">fraction_of_positives</span><span class="p">,</span> 
                                                      <span class="n">confidence</span><span class="o">=</span><span class="n">mean_predicted_value</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'ECE (after calibration): {:.4f}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">ece_post_calibration</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>ECE (after calibration): 0.0000
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plot_reliability_diagram</span><span class="p">(</span><span class="n">calibration_data</span><span class="p">,</span> 
                         <span class="n">lr_test_predictions</span><span class="p">,</span> 
                         <span class="n">ece</span><span class="o">=</span><span class="p">[</span><span class="n">ece_post_calibration</span><span class="p">])</span>
</code></pre></div></div>

<p><img src="/img/Node_Prediction/output_70_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test_predictions</span><span class="p">))</span>
<span class="k">if</span> <span class="n">use_platt</span><span class="p">:</span>
    <span class="c1"># the true predictions are the probabilistic outputs
</span>    <span class="n">test_predictions</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">all_test_probabilistic_predictions</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">y_pred</span><span class="p">[</span><span class="n">test_predictions</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">&gt;</span><span class="mf">0.5</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Accuracy of model before calibration: {:.2f}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">,</span> 
                                                                           <span class="n">y_true</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">test_data</span><span class="p">[</span><span class="s">'depart'</span><span class="p">]))))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Accuracy of model before calibration: 0.92
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">lr_test_predictions</span><span class="p">))</span>
<span class="n">y_pred</span><span class="p">[</span><span class="n">lr_test_predictions</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">&gt;</span><span class="mf">0.5</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="k">print</span><span class="p">(</span><span class="s">'Accuracy for model after calibration: {:.2f}'</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_pred</span><span class="o">=</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_true</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">test_data</span><span class="p">[</span><span class="s">'depart'</span><span class="p">]))))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Accuracy for model after calibration: 0.92
</code></pre></div></div>

<p>Find impotant features</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">big_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"data/big_df_orig.csv"</span><span class="p">)</span>
<span class="n">big_df</span><span class="p">.</span><span class="n">drop</span><span class="p">([</span><span class="s">'Unnamed: 0'</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">big_df</span><span class="p">[</span><span class="s">'Count'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">big_df</span><span class="p">[</span><span class="s">'Count'</span><span class="p">]</span><span class="o">-</span><span class="n">big_df</span><span class="p">[</span><span class="s">'Count'</span><span class="p">].</span><span class="n">mean</span><span class="p">())</span><span class="o">/</span><span class="n">big_df</span><span class="p">[</span><span class="s">'Count'</span><span class="p">].</span><span class="n">std</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">big_df</span><span class="p">.</span><span class="n">columns</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Index(['node', 'deg', 'close', 'between', 'eigen', 'Count', 'depart'], dtype='object')
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">model_selection</span><span class="p">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">big_df</span><span class="p">[[</span><span class="s">'between'</span><span class="p">,</span> <span class="s">'Count'</span><span class="p">,</span> <span class="s">'deg'</span><span class="p">,</span> <span class="s">'close'</span><span class="p">,</span> <span class="s">'eigen'</span><span class="p">]],</span> <span class="n">big_df</span><span class="p">[</span><span class="s">'depart'</span><span class="p">],</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">)</span>
<span class="n">n_train</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">.</span><span class="n">shape</span>
<span class="k">print</span><span class="p">(</span><span class="n">X_train</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X_test</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(5424, 5) (1356, 5)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">n</span><span class="p">,</span> <span class="n">d</span> <span class="o">=</span> <span class="n">big_df</span><span class="p">[[</span><span class="s">'between'</span><span class="p">,</span> <span class="s">'Count'</span><span class="p">,</span> <span class="s">'deg'</span><span class="p">,</span> <span class="s">'close'</span><span class="p">,</span> <span class="s">'eigen'</span><span class="p">]].</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">big_df</span><span class="p">[</span><span class="n">big_df</span><span class="p">[</span><span class="s">'depart'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">][</span><span class="s">'between'</span><span class="p">].</span><span class="n">describe</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>count    6039.000000
mean        0.001111
std         0.011457
min         0.000000
25%         0.000000
50%         0.000000
75%         0.000038
max         0.573032
Name: between, dtype: float64
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">big_df</span><span class="p">[</span><span class="n">big_df</span><span class="p">[</span><span class="s">'depart'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">][</span><span class="s">'between'</span><span class="p">].</span><span class="n">describe</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>count    741.000000
mean       0.000131
std        0.000813
min        0.000000
25%        0.000000
50%        0.000000
75%        0.000000
max        0.016785
Name: between, dtype: float64
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Create Correlation df
</span><span class="n">corr</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">.</span><span class="n">corr</span><span class="p">()</span>
<span class="c1">#Plot figsize
</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="c1">#Generate Color Map
</span><span class="n">colormap</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">diverging_palette</span><span class="p">(</span><span class="mi">220</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">as_cmap</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="c1">#Generate Heat Map, allow annotations and place floats in map
</span><span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">corr</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">colormap</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s">".2f"</span><span class="p">)</span>
<span class="c1">#Apply xticks
</span><span class="n">plt</span><span class="p">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">corr</span><span class="p">.</span><span class="n">columns</span><span class="p">)),</span> <span class="n">corr</span><span class="p">.</span><span class="n">columns</span><span class="p">);</span>
<span class="c1">#Apply yticks
</span><span class="n">plt</span><span class="p">.</span><span class="n">yticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">corr</span><span class="p">.</span><span class="n">columns</span><span class="p">)),</span> <span class="n">corr</span><span class="p">.</span><span class="n">columns</span><span class="p">)</span>
<span class="c1">#show plot
</span><span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/img/Node_Prediction/output_86_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sns</span><span class="p">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/img/Node_Prediction/output_87_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">COV</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">cov</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">COV</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/img/Node_Prediction/output_88_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">U</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="n">svd</span><span class="p">(</span><span class="n">COV</span><span class="p">,</span> <span class="n">full_matrices</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="s">'r-o'</span><span class="p">)</span>
<span class="c1">#plt.axvline(60, c='r')
</span><span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Valeurs singulières de la matrice de corrélation"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/img/Node_Prediction/output_90_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">s</span> <span class="o">&lt;</span> <span class="mf">0.01</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([False,  True,  True,  True,  True])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">len</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>5
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">s</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([1.00154518e+00, 7.86947491e-04, 1.36366655e-04, 1.23305685e-04,
       1.58050399e-07])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span><span class="p">,</span> <span class="n">Ridge</span><span class="p">,</span> <span class="n">LassoCV</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">regr0</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">regr0</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">regr0</span><span class="p">.</span><span class="n">coef_</span><span class="p">,</span> <span class="s">'r-o'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Valeurs des coefficients OLS"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/img/Node_Prediction/output_95_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">regr0</span><span class="p">.</span><span class="n">coef_</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array([-2.25750655e-01,  2.61360005e-02,  7.06336051e+01,  4.24735688e-01,
       -5.19505034e-02])
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_train_reduce</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">U</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">])</span>
<span class="n">X_test_reduce</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">U</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">])</span>

<span class="n">regr1</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">regr1</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_reduce</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">regr1</span><span class="p">.</span><span class="n">coef_</span><span class="p">,</span> <span class="s">'r-o'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Valeurs des coefficients de PCA_before_OLS (sans intercept)"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/img/Node_Prediction/output_97_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="p">(</span><span class="n">regr0</span><span class="p">.</span><span class="n">intercept_</span><span class="p">,</span> <span class="n">regr1</span><span class="p">.</span><span class="n">intercept_</span><span class="p">,</span> <span class="n">y_train</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"%.3f"</span> <span class="o">%</span> <span class="n">y</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">Les deux intercepts sont-ils égaux: %s"</span>
      <span class="o">%</span> <span class="n">np</span><span class="p">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">regr0</span><span class="p">.</span><span class="n">intercept_</span><span class="p">,</span> <span class="n">regr1</span><span class="p">.</span><span class="n">intercept_</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0.822
0.808
0.893

Les deux intercepts sont-ils égaux: False
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">preprocessing</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_train_reduce2</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="p">.</span><span class="n">scale</span><span class="p">(</span><span class="n">X_train_reduce</span><span class="p">)</span>

<span class="n">regrtest</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">regrtest</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_reduce2</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"On vérifie l'égalité. Cette égalité est: %s."</span>
      <span class="o">%</span> <span class="n">np</span><span class="p">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">regrtest</span><span class="p">.</span><span class="n">intercept_</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y_train</span><span class="p">)))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>On vérifie l'égalité. Cette égalité est: True.
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">R20</span> <span class="o">=</span> <span class="n">regr0</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> 
<span class="n">R21</span> <span class="o">=</span> <span class="n">regr1</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_reduce</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">MSE</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_true</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">((</span><span class="n">y_pred</span> <span class="o">-</span> <span class="n">y_true</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">pred_error0</span> <span class="o">=</span> <span class="n">MSE</span><span class="p">(</span><span class="n">regr0</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="n">y_test</span><span class="p">)</span>
<span class="n">pred_error1</span> <span class="o">=</span> <span class="n">MSE</span><span class="p">(</span><span class="n">regr1</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_reduce</span><span class="p">),</span> <span class="n">y_test</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Le R2 de OLS:            %.3f"</span> <span class="o">%</span> <span class="n">R20</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Le R2 de PCA before OLS: %.3f</span><span class="se">\n</span><span class="s">"</span> <span class="o">%</span> <span class="n">R21</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Le rique de prédiction de OLS calculé sur l'échantillon test:            %.2f"</span> <span class="o">%</span> <span class="n">pred_error0</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Le rique de prédiction de PCA before OLS calculé sur l'échantillon test: %.2f"</span> <span class="o">%</span> <span class="n">pred_error1</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Le R2 de OLS:            0.018
Le R2 de PCA before OLS: 0.008

Le rique de prédiction de OLS calculé sur l'échantillon test:            0.10
Le rique de prédiction de PCA before OLS calculé sur l'échantillon test: 0.10
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">eps0</span> <span class="o">=</span> <span class="n">regr0</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span> <span class="o">-</span> <span class="n">y_test</span>
<span class="n">eps1</span> <span class="o">=</span> <span class="n">regr1</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_reduce</span><span class="p">)</span> <span class="o">-</span> <span class="n">y_test</span>

<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">eps0</span><span class="p">.</span><span class="n">values</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">"ols"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">eps1</span><span class="p">.</span><span class="n">values</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">"pca_before_ols"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Visualisation des résidus"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/img/Node_Prediction/output_102_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">eps</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">c_</span><span class="p">[</span><span class="n">eps0</span><span class="p">,</span> <span class="n">eps1</span><span class="p">],</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">'OLS'</span><span class="p">,</span> <span class="s">'PCA_before_OLS'</span><span class="p">])</span>
<span class="n">eps</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/img/Node_Prediction/output_103_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">resids</span> <span class="o">=</span> <span class="n">y_train</span>

<span class="n">test</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">d</span><span class="p">,</span> <span class="n">d</span><span class="p">))</span>
<span class="n">pval_mem</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
<span class="n">pval</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">d</span><span class="p">,</span> <span class="n">d</span><span class="p">))</span>
<span class="n">var_sel</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">var_remain</span> <span class="o">=</span> <span class="p">[</span><span class="s">'between'</span><span class="p">,</span> <span class="s">'Count'</span><span class="p">,</span> <span class="s">'deg'</span><span class="p">,</span> <span class="s">'close'</span><span class="p">,</span> <span class="s">'eigen'</span><span class="p">]</span> <span class="c1">#list(range(d))
</span><span class="n">in_test</span> <span class="o">=</span> <span class="p">[]</span>
 
<span class="n">regr</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">norm</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">d</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>5
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">d</span><span class="p">):</span> 
    <span class="n">resids_mem</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">d</span><span class="p">,</span> <span class="n">n_train</span><span class="p">))</span>
    <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">var_remain</span><span class="p">:</span>
        <span class="n">xtmp</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span> <span class="c1">#X_train[:, [i]]
</span>        <span class="n">xtmp</span> <span class="o">=</span> <span class="n">xtmp</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">regr</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xtmp</span><span class="p">,</span> <span class="n">resids</span><span class="p">)</span>
        
        <span class="c1"># calcul de (x'x)
</span>        <span class="n">xx</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="c1">#xx = np.sum(X_train[:, i] ** 2)
</span>        <span class="n">resids_mem</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">regr</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xtmp</span><span class="p">)</span> <span class="o">-</span> <span class="n">resids</span>
        <span class="n">sigma2_tmp</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">resids_mem</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="p">:]</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">xx</span>
        <span class="n">test</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">regr</span><span class="p">.</span><span class="n">coef_</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">sigma2_tmp</span><span class="p">))</span>
        <span class="n">pval</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">norm</span><span class="p">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">j</span><span class="p">]))</span>
        <span class="n">j</span> <span class="o">=</span> <span class="n">j</span> <span class="o">+</span> <span class="mi">1</span>

    <span class="c1"># separe en deux vecteurs la listes des variables séléctionnées et les autres
</span>    <span class="n">best_var</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="p">:])</span>
    <span class="n">var_sel</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">best_var</span><span class="p">)</span>
    <span class="n">resids</span> <span class="o">=</span> <span class="n">resids_mem</span><span class="p">[</span><span class="n">best_var</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">pval_mem</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">pval</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">best_var</span><span class="p">]</span>
    <span class="n">var_remain</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">setdiff1d</span><span class="p">(</span><span class="n">var_remain</span><span class="p">,</span> <span class="n">var_sel</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Voici l'ordre dans lequel les variables sont sélectionées par la méthode forward :</span><span class="se">\n\n</span><span class="s">%s"</span> <span class="o">%</span> <span class="n">var_sel</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Voici l'ordre dans lequel les variables sont sélectionées par la méthode forward :

[3, 3, 2, 0, 3]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>

<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    
    <span class="n">plt</span><span class="p">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">311</span> <span class="o">+</span> <span class="n">k</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">k</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"values of the t-stat at each step"</span><span class="p">)</span>

    <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">d</span><span class="p">),</span> <span class="n">test</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="p">:],</span> <span class="s">'-o'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">"step %s"</span> <span class="o">%</span> <span class="n">k</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">var_sel</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">test</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">var_sel</span><span class="p">[</span><span class="n">k</span><span class="p">]],</span> <span class="s">'r-o'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">k</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"features"</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/img/Node_Prediction/output_108_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig2</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>

<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span> 
    <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="n">d</span><span class="p">),</span> <span class="n">pval_mem</span><span class="p">,</span> <span class="s">'o'</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">([</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="p">[.</span><span class="mi">1</span><span class="p">,</span> <span class="p">.</span><span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s">"b"</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">axis</span><span class="p">(</span><span class="n">xmin</span><span class="o">=-</span><span class="p">.</span><span class="mi">5</span><span class="p">,</span> <span class="n">xmax</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">ymin</span><span class="o">=-</span><span class="p">.</span><span class="mi">03</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Graph des p-valeurs"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"steps"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/img/Node_Prediction/output_109_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">var_sel_a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">var_sel</span><span class="p">)</span>
<span class="c1">#print(var_sel_a,var_sel)
</span><span class="n">var_sel_def</span> <span class="o">=</span> <span class="n">var_sel_a</span><span class="p">[</span><span class="n">pval_mem</span> <span class="o">&lt;</span> <span class="mf">0.001</span><span class="p">]</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Il y a donc %s variables selectionnées.</span><span class="se">\n</span><span class="s">Les voici: %s"</span> <span class="o">%</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">var_sel_def</span><span class="p">),</span> <span class="n">var_sel_def</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>There are therefore 4 selected variables.
Here they are: [3 3 2 0]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_train</span><span class="p">.</span><span class="n">columns</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Index(['between', 'Count', 'deg', 'close', 'eigen'], dtype='object')
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_train_sel</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[[</span><span class="s">'between'</span><span class="p">,</span> <span class="s">'Count'</span><span class="p">]]</span>
<span class="n">X_test_sel</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">[[</span><span class="s">'between'</span><span class="p">,</span> <span class="s">'Count'</span><span class="p">]]</span>

<span class="n">regr2</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">regr2</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_sel</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">regr2</span><span class="p">.</span><span class="n">coef_</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">regr2</span><span class="p">.</span><span class="n">intercept_</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[0.89524856 0.0158369 ]
0.8918800888752971
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pred_error_forward</span> <span class="o">=</span> <span class="n">MSE</span><span class="p">(</span><span class="n">regr2</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_sel</span><span class="p">),</span> <span class="n">y_test</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="s">"As a reminder, let us give the prediction scores obtained previouslyt.</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>

<span class="k">for</span> <span class="n">method</span><span class="p">,</span> <span class="n">error</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="s">"ols           "</span><span class="p">,</span> <span class="s">"pca_before_ols"</span><span class="p">,</span> <span class="s">"forward       "</span><span class="p">],</span>
                         <span class="p">[</span><span class="n">pred_error0</span><span class="p">,</span> <span class="n">pred_error1</span><span class="p">,</span> <span class="n">pred_error_forward</span><span class="p">]):</span>
    <span class="k">print</span><span class="p">(</span><span class="n">method</span> <span class="o">+</span> <span class="s">" : %.2f"</span> <span class="o">%</span> <span class="n">error</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>As a reminder, let us give the prediction scores obtained previouslyt.

ols            : 0.10
pca_before_ols : 0.10
forward        : 0.10
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">perm</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">permutation</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_train</span><span class="p">))</span>
<span class="n">q</span> <span class="o">=</span> <span class="n">n_train</span> <span class="o">/</span> <span class="mf">4.</span>
<span class="n">split</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span> <span class="o">*</span> <span class="n">q</span>
<span class="n">split</span> <span class="o">=</span> <span class="n">split</span><span class="p">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

<span class="k">for</span> <span class="n">fold</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"The fold %s contains:</span><span class="se">\n</span><span class="s">%s</span><span class="se">\n\n</span><span class="s">"</span> <span class="o">%</span> <span class="p">(</span><span class="n">fold</span><span class="p">,</span> <span class="n">perm</span><span class="p">[</span><span class="n">split</span><span class="p">[</span><span class="n">fold</span><span class="p">]:</span> <span class="n">split</span><span class="p">[</span><span class="n">fold</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]]))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>The fold 0 contains:
[2486  738 4875 ... 3688 3723 1036]


The fold 1 containst:
[2491  857 3734 ... 4839 1668 2992]


The fold 2 contains:
[2659 1106 5196 ... 4191 3589 4707]


The fold 3 contains:
[5070 2885  249 ... 2514 3606 2575]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lasso</span> <span class="o">=</span> <span class="n">LassoCV</span><span class="p">()</span>
<span class="n">lasso</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># The estimator chose automatically its lambda:
</span><span class="n">lasso</span><span class="p">.</span><span class="n">alpha_</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2.1532196265600495e-05
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pred_error_lasso</span> <span class="o">=</span> <span class="n">MSE</span><span class="p">(</span><span class="n">lasso</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">),</span> <span class="n">y_test</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="s">"As a reminder, let's give the scores obtained previously.</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>

<span class="k">for</span> <span class="n">method</span><span class="p">,</span> <span class="n">error</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="s">"ols           "</span><span class="p">,</span> <span class="s">"pca_before_ols"</span><span class="p">,</span> <span class="s">"forward       "</span><span class="p">,</span>
                          <span class="s">"lasso         "</span><span class="p">],</span>
                         <span class="p">[</span><span class="n">pred_error0</span><span class="p">,</span> <span class="n">pred_error1</span><span class="p">,</span> <span class="n">pred_error_forward</span><span class="p">,</span>
                           <span class="n">pred_error_lasso</span><span class="p">]):</span>
    <span class="k">print</span><span class="p">(</span><span class="n">method</span> <span class="o">+</span> <span class="s">" : %.2f"</span> <span class="o">%</span> <span class="n">error</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>As a reminder, let's give the scores obtained previously.

ols            : 0.10
pca_before_ols : 0.10
forward        : 0.10
lasso          : 0.10
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">SelectKBest</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">chi2</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">big_df</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">big_df_</span> <span class="o">=</span> <span class="n">big_df</span>
<span class="n">big_df_</span><span class="p">[[</span><span class="s">'deg'</span><span class="p">,</span> <span class="s">'close'</span><span class="p">,</span> <span class="s">'between'</span><span class="p">,</span> <span class="s">'eigen'</span><span class="p">,</span> <span class="s">'Count'</span><span class="p">]]</span> <span class="o">=</span> <span class="n">big_df_</span><span class="p">[[</span><span class="s">'deg'</span><span class="p">,</span> <span class="s">'close'</span><span class="p">,</span> <span class="s">'between'</span><span class="p">,</span> <span class="s">'eigen'</span><span class="p">,</span> <span class="s">'Count'</span><span class="p">]]</span><span class="o">*</span><span class="mi">1000</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">big_df_</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">big_df</span><span class="p">.</span><span class="n">columns</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Index(['deg', 'close', 'between', 'eigen', 'Count', 'depart'], dtype='object')
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X</span> <span class="o">=</span> <span class="n">big_df</span><span class="p">[[</span><span class="s">'deg'</span><span class="p">,</span> <span class="s">'close'</span><span class="p">,</span> <span class="s">'between'</span><span class="p">,</span> <span class="s">'eigen'</span><span class="p">,</span> <span class="s">'Count'</span><span class="p">]]</span>  <span class="c1">#independent columns
</span><span class="n">y</span> <span class="o">=</span> <span class="n">big_df</span><span class="p">[[</span><span class="s">'depart'</span><span class="p">]]</span>    <span class="c1">#target column i.e price range
</span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">ExtraTreesClassifier</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ExtraTreesClassifier</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">feature_importances_</span><span class="p">)</span> <span class="c1">#use inbuilt class feature_importances of tree based classifiers
#plot graph of feature importances for better visualization
</span><span class="n">feat_importances</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">feature_importances_</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">X</span><span class="p">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">feat_importances</span><span class="p">.</span><span class="n">nlargest</span><span class="p">(</span><span class="mi">5</span><span class="p">).</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s">'barh'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[0.02971642 0.32936866 0.03982511 0.1503454  0.45074441]


/home/arij/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.
  "10 in version 0.20 to 100 in 0.22.", FutureWarning)
/home/arij/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().
</code></pre></div></div>

<p><img src="/img/Node_Prediction/output_124_2.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X</span> <span class="o">=</span> <span class="n">big_df_</span><span class="p">[[</span><span class="s">'deg'</span><span class="p">,</span> <span class="s">'close'</span><span class="p">,</span> <span class="s">'between'</span><span class="p">,</span> <span class="s">'eigen'</span><span class="p">,</span> <span class="s">'Count'</span><span class="p">]]</span>  <span class="c1">#independent columns
</span><span class="n">y</span> <span class="o">=</span> <span class="n">big_df_</span><span class="p">[[</span><span class="s">'depart'</span><span class="p">]]</span>    <span class="c1">#target column i.e price range
</span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">ExtraTreesClassifier</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ExtraTreesClassifier</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">feature_importances_</span><span class="p">)</span> <span class="c1">#use inbuilt class feature_importances of tree based classifiers
#plot graph of feature importances for better visualization
</span><span class="n">feat_importances</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">feature_importances_</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">X</span><span class="p">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">feat_importances</span><span class="p">.</span><span class="n">nlargest</span><span class="p">(</span><span class="mi">5</span><span class="p">).</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s">'barh'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[0.02684944 0.29080116 0.03635093 0.21448593 0.43151254]
</code></pre></div></div>

<p><img src="/img/Node_Prediction/output_124_2.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="n">sm</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">RFE</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">RidgeCV</span><span class="p">,</span> <span class="n">LassoCV</span><span class="p">,</span> <span class="n">Ridge</span><span class="p">,</span> <span class="n">Lasso</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">big_df</span><span class="p">.</span><span class="n">columns</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Index(['node', 'deg', 'close', 'between', 'eigen', 'Count', 'depart'], dtype='object')
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Adding constant column of ones, mandatory for sm.OLS model
</span><span class="n">X_1</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="c1">#Fitting sm.OLS model
</span><span class="n">model</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">X_1</span><span class="p">).</span><span class="n">fit</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="n">pvalues</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>const      0.000000e+00
deg        1.460348e-13
close      9.604029e-04
between    5.430823e-01
eigen      7.315541e-01
Count      1.949169e-10
dtype: float64
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Backward Elimination
</span><span class="n">cols</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">pmax</span> <span class="o">=</span> <span class="mi">1</span>
<span class="k">while</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">cols</span><span class="p">)</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">):</span>
    <span class="n">p</span><span class="o">=</span> <span class="p">[]</span>
    <span class="n">X_1</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">cols</span><span class="p">]</span>
    <span class="n">X_1</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">X_1</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">y</span><span class="p">,</span><span class="n">X_1</span><span class="p">).</span><span class="n">fit</span><span class="p">()</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">pvalues</span><span class="p">.</span><span class="n">values</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span><span class="n">index</span> <span class="o">=</span> <span class="n">cols</span><span class="p">)</span>      
    <span class="n">pmax</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
    <span class="n">feature_with_p_max</span> <span class="o">=</span> <span class="n">p</span><span class="p">.</span><span class="n">idxmax</span><span class="p">()</span>
    <span class="k">if</span><span class="p">(</span><span class="n">pmax</span><span class="o">&gt;</span><span class="mf">0.05</span><span class="p">):</span>
        <span class="n">cols</span><span class="p">.</span><span class="n">remove</span><span class="p">(</span><span class="n">feature_with_p_max</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">break</span>
<span class="n">selected_features_BE</span> <span class="o">=</span> <span class="n">cols</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">selected_features_BE</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>['deg', 'close', 'Count']
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="c1">#Initializing RFE model
</span><span class="n">rfe</span> <span class="o">=</span> <span class="n">RFE</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="c1">#Transforming data using RFE
</span><span class="n">X_rfe</span> <span class="o">=</span> <span class="n">rfe</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>  
<span class="c1">#Fitting the data to model
</span><span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_rfe</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">rfe</span><span class="p">.</span><span class="n">support_</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">rfe</span><span class="p">.</span><span class="n">ranking_</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[ True  True  True  True  True]
[1 1 1 1 1]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#no of features
</span><span class="n">nof_list</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">13</span><span class="p">)</span>            
<span class="n">high_score</span><span class="o">=</span><span class="mi">0</span>
<span class="c1">#Variable to store the optimum features
</span><span class="n">nof</span><span class="o">=</span><span class="mi">0</span>           
<span class="n">score_list</span> <span class="o">=</span><span class="p">[]</span>
<span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">nof_list</span><span class="p">)):</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">model_selection</span><span class="p">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
    <span class="n">rfe</span> <span class="o">=</span> <span class="n">RFE</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="n">nof_list</span><span class="p">[</span><span class="n">n</span><span class="p">])</span>
    <span class="n">X_train_rfe</span> <span class="o">=</span> <span class="n">rfe</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
    <span class="n">X_test_rfe</span> <span class="o">=</span> <span class="n">rfe</span><span class="p">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_rfe</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_rfe</span><span class="p">,</span><span class="n">y_test</span><span class="p">)</span>
    <span class="n">score_list</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
    <span class="k">if</span><span class="p">(</span><span class="n">score</span><span class="o">&gt;</span><span class="n">high_score</span><span class="p">):</span>
        <span class="n">high_score</span> <span class="o">=</span> <span class="n">score</span>
        <span class="n">nof</span> <span class="o">=</span> <span class="n">nof_list</span><span class="p">[</span><span class="n">n</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Optimum number of features: %d"</span> <span class="o">%</span><span class="n">nof</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Score with %d features: %f"</span> <span class="o">%</span> <span class="p">(</span><span class="n">nof</span><span class="p">,</span> <span class="n">high_score</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Optimum number of features: 1
Score with 1 features: 0.005617
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cols</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">X</span><span class="p">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="c1">#Initializing RFE model
</span><span class="n">rfe</span> <span class="o">=</span> <span class="n">RFE</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>             
<span class="c1">#Transforming data using RFE
</span><span class="n">X_rfe</span> <span class="o">=</span> <span class="n">rfe</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>  
<span class="c1">#Fitting the data to model
</span><span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_rfe</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>              
<span class="n">temp</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">(</span><span class="n">rfe</span><span class="p">.</span><span class="n">support_</span><span class="p">,</span><span class="n">index</span> <span class="o">=</span> <span class="n">cols</span><span class="p">)</span>
<span class="n">selected_features_rfe</span> <span class="o">=</span> <span class="n">temp</span><span class="p">[</span><span class="n">temp</span><span class="o">==</span><span class="bp">True</span><span class="p">].</span><span class="n">index</span>
<span class="k">print</span><span class="p">(</span><span class="n">selected_features_rfe</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Index(['deg'], dtype='object')
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">reg</span> <span class="o">=</span> <span class="n">LassoCV</span><span class="p">()</span>
<span class="n">reg</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Best alpha using built-in LassoCV: %f"</span> <span class="o">%</span> <span class="n">reg</span><span class="p">.</span><span class="n">alpha_</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Best score using built-in LassoCV: %f"</span> <span class="o">%</span><span class="n">reg</span><span class="p">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">))</span>
<span class="n">coef</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">(</span><span class="n">reg</span><span class="p">.</span><span class="n">coef_</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="n">columns</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Best alpha using built-in LassoCV: 0.000040
Best score using built-in LassoCV: 0.009326
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="s">"Lasso picked "</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">coef</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">))</span> <span class="o">+</span> <span class="s">" variables and eliminated the other "</span> <span class="o">+</span>  <span class="nb">str</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">coef</span> <span class="o">==</span> <span class="mi">0</span><span class="p">))</span> <span class="o">+</span> <span class="s">" variables"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Lasso picked 4 variables and eliminated the other 1 variables
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">imp_coef</span> <span class="o">=</span> <span class="n">coef</span><span class="p">.</span><span class="n">sort_values</span><span class="p">()</span>
<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="n">matplotlib</span><span class="p">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s">'figure.figsize'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mf">8.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">)</span>
<span class="n">imp_coef</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span> <span class="o">=</span> <span class="s">"barh"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Feature importance using Lasso Model"</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/img/Node_Prediction/output_136_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">feature_selector</span> <span class="kn">import</span> <span class="n">FeatureSelector</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fs</span> <span class="o">=</span> <span class="n">FeatureSelector</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">X</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fs</span><span class="p">.</span><span class="n">identify_missing</span><span class="p">(</span><span class="n">missing_threshold</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">)</span>
<span class="n">fs</span><span class="p">.</span><span class="n">missing_stats</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0 features with greater than 0.60 missing values.
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fs</span><span class="p">.</span><span class="n">identify_collinear</span><span class="p">(</span><span class="n">correlation_threshold</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0 features with a correlation magnitude greater than 0.50.
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Pass in the appropriate parameters
</span><span class="n">fs</span><span class="p">.</span><span class="n">identify_zero_importance</span><span class="p">(</span><span class="n">task</span> <span class="o">=</span> <span class="s">'classification'</span><span class="p">,</span> 
                            <span class="n">eval_metric</span> <span class="o">=</span> <span class="s">'auc'</span><span class="p">,</span> 
                            <span class="n">n_iterations</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> 
                             <span class="n">early_stopping</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="c1"># list of zero importance features
</span><span class="n">zero_importance_features</span> <span class="o">=</span> <span class="n">fs</span><span class="p">.</span><span class="n">ops</span><span class="p">[</span><span class="s">'zero_importance'</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Training Gradient Boosting Model

Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[113]	valid_0's auc: 0.918258	valid_0's binary_logloss: 0.166625
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[136]	valid_0's auc: 0.920733	valid_0's binary_logloss: 0.16579
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[114]	valid_0's auc: 0.933337	valid_0's binary_logloss: 0.150962
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[87]	valid_0's auc: 0.92038	valid_0's binary_logloss: 0.168393
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[50]	valid_0's auc: 0.92073	valid_0's binary_logloss: 0.188329
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[105]	valid_0's auc: 0.913405	valid_0's binary_logloss: 0.169875
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[100]	valid_0's auc: 0.944989	valid_0's binary_logloss: 0.148649
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[62]	valid_0's auc: 0.903135	valid_0's binary_logloss: 0.207652
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[92]	valid_0's auc: 0.938784	valid_0's binary_logloss: 0.149928
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[115]	valid_0's auc: 0.910397	valid_0's binary_logloss: 0.191539

0 features with zero importance after one-hot encoding.
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># plot the feature importances
</span><span class="n">fs</span><span class="p">.</span><span class="n">plot_feature_importances</span><span class="p">(</span><span class="n">threshold</span> <span class="o">=</span> <span class="mf">0.99</span><span class="p">,</span> <span class="n">plot_n</span> <span class="o">=</span> <span class="mi">12</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/img/Node_Prediction/output_142_0.png" alt="png" /></p>

<p><img src="/img/Node_Prediction/output_142_1.png" alt="png" /></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>5 features required for 0.99 of cumulative importance
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fs</span><span class="p">.</span><span class="n">identify_low_importance</span><span class="p">(</span><span class="n">cumulative_importance</span> <span class="o">=</span> <span class="mf">0.99</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>4 features required for cumulative importance of 0.99 after one hot encoding.
1 features do not contribute to cumulative importance of 0.99.
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fs</span><span class="p">.</span><span class="n">identify_single_unique</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0 features with a single unique value.
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fs</span><span class="p">.</span><span class="n">plot_unique</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="/img/Node_Prediction/output_145_0.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_removed</span> <span class="o">=</span> <span class="n">fs</span><span class="p">.</span><span class="n">remove</span><span class="p">(</span><span class="n">methods</span> <span class="o">=</span> <span class="s">'all'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>['missing', 'collinear', 'zero_importance', 'low_importance', 'single_unique'] methods have been run

Removed 1 features.
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_removed</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_removed_all</span> <span class="o">=</span> <span class="n">fs</span><span class="p">.</span><span class="n">remove</span><span class="p">(</span><span class="n">methods</span> <span class="o">=</span> <span class="s">'all'</span><span class="p">,</span> <span class="n">keep_one_hot</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>['missing', 'collinear', 'zero_importance', 'low_importance', 'single_unique'] methods have been run

Removed 1 features including one-hot features.
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_removed_all</span><span class="p">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fs</span><span class="p">.</span><span class="n">identify_all</span><span class="p">(</span><span class="n">selection_params</span> <span class="o">=</span> <span class="p">{</span><span class="s">'missing_threshold'</span><span class="p">:</span> <span class="mf">0.6</span><span class="p">,</span>    
                                    <span class="s">'correlation_threshold'</span><span class="p">:</span> <span class="mf">0.98</span><span class="p">,</span> 
                                    <span class="s">'task'</span><span class="p">:</span> <span class="s">'classification'</span><span class="p">,</span>    
                                    <span class="s">'eval_metric'</span><span class="p">:</span> <span class="s">'auc'</span><span class="p">,</span> 
                                    <span class="s">'cumulative_importance'</span><span class="p">:</span> <span class="mf">0.99</span><span class="p">})</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0 features with greater than 0.60 missing values.

0 features with a single unique value.

0 features with a correlation magnitude greater than 0.98.

Training Gradient Boosting Model

Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[99]	valid_0's auc: 0.910872	valid_0's binary_logloss: 0.186959
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[102]	valid_0's auc: 0.892063	valid_0's binary_logloss: 0.186904
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[74]	valid_0's auc: 0.921257	valid_0's binary_logloss: 0.187569
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[120]	valid_0's auc: 0.922538	valid_0's binary_logloss: 0.170568
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[79]	valid_0's auc: 0.923534	valid_0's binary_logloss: 0.163693
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[147]	valid_0's auc: 0.92	valid_0's binary_logloss: 0.17738
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[35]	valid_0's auc: 0.916405	valid_0's binary_logloss: 0.18372
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[136]	valid_0's auc: 0.910572	valid_0's binary_logloss: 0.190256
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[106]	valid_0's auc: 0.919383	valid_0's binary_logloss: 0.166765
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[107]	valid_0's auc: 0.914182	valid_0's binary_logloss: 0.175298

0 features with zero importance after one-hot encoding.

4 features required for cumulative importance of 0.99 after one hot encoding.
1 features do not contribute to cumulative importance of 0.99.

1 total features out of 5 identified for removal after one-hot encoding.
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">nodes_with_conflict</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">ddf</span><span class="p">[</span><span class="n">ddf</span><span class="p">[</span><span class="s">'conflict'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">][</span><span class="s">'IndividualId'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">nodes_without_conflict</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">ddf</span><span class="p">[</span><span class="n">ddf</span><span class="p">[</span><span class="s">'conflict'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">][</span><span class="s">'IndividualId'</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">set</span><span class="p">(</span><span class="n">nodes_with_conflict</span><span class="p">)</span> <span class="o">==</span> <span class="nb">set</span><span class="p">(</span><span class="n">nodes_without_conflict</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>False
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">big_df_with_conflict</span> <span class="o">=</span> <span class="n">big_df</span><span class="p">[</span><span class="n">big_df</span><span class="p">[</span><span class="s">'node'</span><span class="p">].</span><span class="n">isin</span><span class="p">(</span><span class="n">nodes_with_conflict</span><span class="p">)]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">big_df_without_conflict</span> <span class="o">=</span> <span class="n">big_df</span><span class="p">[</span><span class="n">big_df</span><span class="p">[</span><span class="s">'node'</span><span class="p">].</span><span class="n">isin</span><span class="p">(</span><span class="n">nodes_without_conflict</span><span class="p">)]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">pandarallel</span> <span class="kn">import</span> <span class="n">pandarallel</span>
<span class="n">pandarallel</span><span class="p">.</span><span class="n">initialize</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">inv</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">x</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">0</span>
    <span class="k">elif</span> <span class="n">x</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">1</span>
<span class="n">big_df</span><span class="p">[</span><span class="s">'depart'</span><span class="p">]</span> <span class="o">=</span> <span class="n">big_df</span><span class="p">[</span><span class="s">'depart'</span><span class="p">].</span><span class="n">parallel_apply</span><span class="p">(</span><span class="n">inv</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>New pandarallel memory created - Size: 2000 MB
Pandarallel will run on 8 workers
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X</span> <span class="o">=</span> <span class="n">big_df_with_conflict</span><span class="p">[[</span><span class="s">'close'</span><span class="p">,</span> <span class="s">'between'</span><span class="p">,</span> <span class="s">'eigen'</span><span class="p">]]</span>  <span class="c1">#independent columns
</span><span class="n">y</span> <span class="o">=</span> <span class="n">big_df_with_conflict</span><span class="p">[[</span><span class="s">'depart'</span><span class="p">]]</span>    <span class="c1">#target column i.e price range
</span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">ExtraTreesClassifier</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ExtraTreesClassifier</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">feature_importances_</span><span class="p">)</span> <span class="c1">#use inbuilt class feature_importances of tree based classifiers
#plot graph of feature importances for better visualization
</span><span class="n">feat_importances</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">feature_importances_</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">X</span><span class="p">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">feat_importances</span><span class="p">.</span><span class="n">nlargest</span><span class="p">(</span><span class="mi">5</span><span class="p">).</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s">'barh'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[0.59650393 0.09559814 0.30789793]
</code></pre></div></div>

<p><img src="/img/Node_Prediction/output_157_2.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X</span> <span class="o">=</span> <span class="n">big_df_without_conflict</span><span class="p">[[</span><span class="s">'close'</span><span class="p">,</span> <span class="s">'between'</span><span class="p">,</span> <span class="s">'eigen'</span><span class="p">]]</span>  <span class="c1">#independent columns
</span><span class="n">y</span> <span class="o">=</span> <span class="n">big_df_without_conflict</span><span class="p">[[</span><span class="s">'depart'</span><span class="p">]]</span>    <span class="c1">#target column i.e price range
</span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">ExtraTreesClassifier</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ExtraTreesClassifier</span><span class="p">()</span>
<span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">feature_importances_</span><span class="p">)</span> <span class="c1">#use inbuilt class feature_importances of tree based classifiers
#plot graph of feature importances for better visualization
</span><span class="n">feat_importances</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">feature_importances_</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">X</span><span class="p">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">feat_importances</span><span class="p">.</span><span class="n">nlargest</span><span class="p">(</span><span class="mi">5</span><span class="p">).</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s">'barh'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[0.59563847 0.07901322 0.32534832]
</code></pre></div></div>

<p><img src="/img/Node_Prediction/output_158_2.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">len</span><span class="p">(</span><span class="n">big_df_with_conflict</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">big_df_without_conflict</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(5915, 780)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fs</span> <span class="o">=</span> <span class="n">FeatureSelector</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">X</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">y</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fs</span><span class="p">.</span><span class="n">identify_collinear</span><span class="p">(</span><span class="n">correlation_threshold</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2 features with a correlation magnitude greater than 0.50.
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Pass in the appropriate parameters
</span><span class="n">fs</span><span class="p">.</span><span class="n">identify_zero_importance</span><span class="p">(</span><span class="n">task</span> <span class="o">=</span> <span class="s">'classification'</span><span class="p">,</span> 
                            <span class="n">eval_metric</span> <span class="o">=</span> <span class="s">'auc'</span><span class="p">,</span> 
                            <span class="n">n_iterations</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> 
                             <span class="n">early_stopping</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="c1"># list of zero importance features
</span><span class="n">zero_importance_features</span> <span class="o">=</span> <span class="n">fs</span><span class="p">.</span><span class="n">ops</span><span class="p">[</span><span class="s">'zero_importance'</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Training Gradient Boosting Model

Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[91]	valid_0's auc: 0.990654	valid_0's binary_logloss: 0.106263
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[164]	valid_0's auc: 0.973625	valid_0's binary_logloss: 0.149786
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[103]	valid_0's auc: 0.939869	valid_0's binary_logloss: 0.197257
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[3]	valid_0's auc: 0.972772	valid_0's binary_logloss: 0.339178
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[27]	valid_0's auc: 0.974852	valid_0's binary_logloss: 0.173048
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[126]	valid_0's auc: 0.942535	valid_0's binary_logloss: 0.217243
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[19]	valid_0's auc: 0.886644	valid_0's binary_logloss: 0.292342
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[85]	valid_0's auc: 0.924411	valid_0's binary_logloss: 0.209373
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[113]	valid_0's auc: 0.956186	valid_0's binary_logloss: 0.202166
Training until validation scores don't improve for 100 rounds
Early stopping, best iteration is:
[55]	valid_0's auc: 0.94248	valid_0's binary_logloss: 0.230042

0 features with zero importance after one-hot encoding.
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fs</span><span class="p">.</span><span class="n">identify_low_importance</span><span class="p">(</span><span class="n">cumulative_importance</span> <span class="o">=</span> <span class="mf">0.99</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>4 features required for cumulative importance of 0.99 after one hot encoding.
1 features do not contribute to cumulative importance of 0.99.
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#train_removed_all = fs.remove(methods = 'all', keep_one_hot=False)
</span><span class="n">train_removed_all</span> <span class="o">=</span> <span class="n">fs</span><span class="p">.</span><span class="n">remove</span><span class="p">(</span><span class="n">methods</span> <span class="o">=</span> <span class="s">'all'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>['collinear', 'zero_importance', 'low_importance'] methods have been run

Removed 3 features.
</code></pre></div></div>


           <!-- <hr />
			<div class="pg-center">

<div class="comments">
  <h2>Comments</h2>
  <div id="disqus_thread"></div>
  <script>
var disqus_config = function () {
  this.page.url = '/machine%20learning/2021/04/25/NodeClassification/'; // Replace PAGE_URL with your page's canonical URL variable
  this.page.identifier = '/machine%20learning/2021/04/25/NodeClassification'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
(function() {
  var d = document, s = d.createElement('script');
  s.src = '//thearchitect-page-disqus-com.disqus.com/embed.js';
  s.setAttribute('data-timestamp', +new Date());
  (d.head || d.body).appendChild(s);
})();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
</div>

</div>
<style>
.pg-center{
background:#ffffff;
padding-top:2rem;
padding-bottom:2rem;
margin-top:2rem;
}
</style>
  
		<hr /> -->		    
            </div>
          </article><!-- /.card -->
        </div>
		<style>
  h4.card-title{
    color: #EA950B;
  }
</style>

<div class="col-md-3 ml-auto">
<!-- 
          <aside class="sidebar">
            <div class="card mb-4">
              <div class="card-body">
                <h4 class="card-title">About</h4>
                <p class="card-text"></p>
              </div>
            </div>
          </aside>
        -->
		  
          <aside class="sidebar sidebar-sticky">
            <div class="card mb-4">
              <div class="card-body">
                <h4 class="card-title">Categories</h4>
				
				    
                <a class="btn btn-link btn-sm mb-1" href="/categories/#Computer Science"> 
                Computer Science,</a>
				
				    
                <a class="btn btn-link btn-sm mb-1" href="/categories/#Artificial Intelligence"> 
                Artificial Intelligence,</a>
				
				    
                <a class="btn btn-link btn-sm mb-1" href="/categories/#Data Science"> 
                Data Science,</a>
				
				    
                <a class="btn btn-link btn-sm mb-1" href="/categories/#Graph Theory"> 
                Graph Theory,</a>
				
				    
                <a class="btn btn-link btn-sm mb-1" href="/categories/#Machine Learning"> 
                Machine Learning</a>
				
              </div>
            </div>
            <div class="card mb-4">
              <div class="card-body">
                
				<h4 class="card-title">Latest posts</h4>
				
                <a href="/data%20science/2021/05/01/MP/" class="d-inline-block">
                  <h4 class="h6">How to use MongoDb with Python</h4>
                  
				  <img class="card-img" src="/img/MongoDB_Python.png" alt="" />
				  
                </a>
				<br />
                <time>On 01 May 2021</time> in Data Science
				<hr />
				
                <a href="/data%20science/2021/04/26/PN/" class="d-inline-block">
                  <h4 class="h6">How to transfer a Python graph to a Neo4j graph</h4>
                  
				  <img class="card-img" src="/img/pton.png" alt="" />
				  
                </a>
				<br />
                <time>On 26 Apr 2021</time> in Data Science
				<hr />
				
              </div>
            </div>
          </aside>

        </div>
	
      </div>
    </div>
  </main>
<!--   <div class="site-newsletter">
    <div class="container">
      <div class="text-center">
        <h3 class="h4 mb-2">Subscribe to our newsletter</h3>
        <p class="text-muted">Join our monthly newsletter and never miss out on new stories and promotions.</p>

        <div class="row">
          <div class="col-xs-12 col-sm-9 col-md-7 col-lg-5 ml-auto mr-auto">
            <div class="input-group mb-3 mt-3">
              <input type="text" class="form-control" placeholder="Email address" aria-label="Email address">
              <span class="input-group-btn">
                <button class="btn btn-secondary" type="button">Subscribe</button>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
 -->
  <footer class="site-footer bg-darkest" role="contentinfo">
    <div class="container">

<!--       <ul class="nav justify-content-center">
        <li class="nav-item">
          <a class="nav-link" href="#">Privacy policy</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="#">Feedback</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="#">Contact</a>
        </li>
      </ul> -->
      <div class="copy">
        &copy;  2021<br />
        All rights reserved
        <a href="https://www.linkedin.com/in/ia-ds-bg/" title="Linkedin"><i class="fab fa-linkedin-square"></i></a>
        <a href="https://github.com/AbdelfattahAbouelaoualim" title="Github"><i class="fab fa-github-square"></i></a>
        <a href="mailto:aa.mlexpert@gmail.com" title="Email me"><i class="fas fa-envelope-square"></i></a>
      </div>
    </div>
  </footer>
  
  <script src="/js/bundle.js"></script>

</body>
</html>
